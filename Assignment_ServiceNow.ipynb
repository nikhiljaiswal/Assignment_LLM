{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FLAN-T5 Model](https://arxiv.org/pdf/2210.11416v5.pdf)\n",
    "\n",
    "**Finetuning language models** on a collection of **datasets phrased as instructions** has been shown to improve\n",
    "model performance and generalization to unseen tasks. In this paper we explore instruction finetuning\n",
    "with a particular focus on **(1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on\n",
    "chain-of-thought data.** We find that instruction finetuning with the above aspects dramatically improves\n",
    "performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT),\n",
    "and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation, RealToxicityPrompts).\n",
    "For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PaLM 540B by a large margin\n",
    "(+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as\n",
    "75.2% on five-shot MMLU. We also **publicly release Flan-T5 checkpoints**,1 which achieve strong few-shot\n",
    "performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a\n",
    "general method for improving the performance and usability of pretrained language models.\n",
    "\n",
    "### [google/flan-t5-small](https://huggingface.co/google/flan-t5-small)\n",
    "80M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./flan_env/lib/python3.10/site-packages (4.19.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m402.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m357.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./flan_env/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./flan_env/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./flan_env/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./flan_env/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./flan_env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./flan_env/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./flan_env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./flan_env/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./flan_env/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./flan_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./flan_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./flan_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./flan_env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./flan_env/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./flan_env/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.19.2\n",
      "    Uninstalling transformers-4.19.2:\n",
      "      Successfully uninstalled transformers-4.19.2\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.3\n",
      "Requirement already satisfied: datasets in ./flan_env/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in ./flan_env/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./flan_env/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./flan_env/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./flan_env/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./flan_env/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./flan_env/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./flan_env/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./flan_env/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./flan_env/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./flan_env/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in ./flan_env/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in ./flan_env/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./flan_env/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in ./flan_env/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./flan_env/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./flan_env/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./flan_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./flan_env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./flan_env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./flan_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Use a pre-trained google/flan-t5-small as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name=\"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import GenerationConfig\n",
    "generation_config = GenerationConfig(max_new_tokens=100)\n",
    "#generation_config = GenerationConfig(max_new_tokens=100,  do_sample=True, temperature=0.1)\n",
    "\n",
    "def generate_llm_prediction(prompt):\n",
    "    #print(f\"\\n========== Input Prompt ===============\\n{prompt}\")\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    output = tokenizer.decode(model.generate(inputs[\"input_ids\"],generation_config=generation_config)[0],skip_special_tokens=True)\n",
    "    output = re.sub('---*','',str(output))\n",
    "    #print(f\"Output:\\n{output}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Task 2: Verify if the summarization task works.\n",
    "\n",
    "For this task, let's take some examples from DialogSum dataset and observe the performance on these examples\n",
    "\n",
    "[DialogSum Dataset](https://huggingface.co/datasets/knkarthick/dialogsum): DialogSum is a large-scale **dialogue summarization dataset**, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding manually labeled summaries and topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 12460\n",
      "Test dataset size: 1500\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = datasets.load_dataset(dataset_name)\n",
    "\n",
    "TRAINING_DATA_COUNT = len(dataset['train'])\n",
    "TEST_DATA_COUNT = len(dataset['test'])\n",
    "\n",
    "print(f\"Train dataset size: {TRAINING_DATA_COUNT}\")\n",
    "print(f\"Test dataset size: {TEST_DATA_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      ">> Index: 0\n",
      "\n",
      "== Dialogue:\n",
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n",
      "\n",
      "== Summary:\n",
      "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n",
      "====================================================================================================\n",
      ">> Index: 40\n",
      "\n",
      "== Dialogue:\n",
      "#Person1#: I just bought a new dress. What do you think of it?\n",
      "#Person2#: You look really great in it. So are you going to a job interview or a party?\n",
      "#Person1#: No, I was invited to give a talk in my school.\n",
      "#Person2#: So how much did you pay for it?\n",
      "#Person1#: I pay just $70 for it. I saved $30.\n",
      "#Person2#: That's really a bargain.\n",
      "#Person1#: You're right. Well, what did you do while I was out shopping?\n",
      "#Person2#: I watched TV for a while and then I did some reading. It wasn't a very interesting book so I just read a few pages. Then I took a shower.\n",
      "#Person1#: I thought you said you were going to see Mike.\n",
      "#Person2#: I'll go and visit him at his home tomorrow. He'll return home tomorrow morning.\n",
      "#Person1#: I'm glad he can finally returned home after that accident.\n",
      "\n",
      "== Summary:\n",
      "While #Person1# made a bargain to buy a new dress, #Person2# watched TV, read a boring book, and took a shower at home.\n",
      "====================================================================================================\n",
      ">> Index: 60\n",
      "\n",
      "== Dialogue:\n",
      "#Person1#: Jenny, are you having a good time?\n",
      "#Person2#: Yes, of course. This is a really wonderful party with interesting people and great food.\n",
      "#Person1#: I'm glad you are enjoying yourself.\n",
      "#Person2#: Thank you for the invitation.\n",
      "#Person1#: It's my pleasure. Can I get you another glass of champagne?\n",
      "#Person2#: Yes, I'd love another glass. You're a wonderful host. Thank you for everything.\n",
      "#Person1#: It's my pleasure having you here.\n",
      "\n",
      "== Summary:\n",
      "Jenny had a good time at #Person1#'s party and she thanks #Person1#.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def visualize_dataset(dataset: datasets.Dataset, indices: list[int] = None) -> None:\n",
    "    if not indices:\n",
    "        # Generate a list of 5 random integers from the training data range\n",
    "        indices = random.sample(range(TRAINING_DATA_COUNT), 5)\n",
    "    for index in indices:\n",
    "        print('='*100)\n",
    "        print(f'>> Index: {index}')\n",
    "        if index < 0 or index > TRAINING_DATA_COUNT:\n",
    "            print(f\"Incorrect Index: {index}\")\n",
    "            continue\n",
    "        print(f'\\n== Dialogue:\\n{dataset[\"train\"][index][\"dialogue\"]}')\n",
    "        print(f'\\n== Summary:\\n{dataset[\"train\"][index][\"summary\"]}')\n",
    "\n",
    "#visualize_dataset(dataset)\n",
    "visualize_dataset(dataset, indices=[0,40,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt(dialogue: str, prompt_index: int) -> str:\n",
    "    if prompt_index == 1:\n",
    "        summarization_zero_shot_prompt = f\"\"\"Summarize the following Dialogue\\n\\nDialogue:\\n{dialogue}\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        summarization_zero_shot_prompt = f\"\"\"Generate a concise summary of the following Dialogue\\n\\nDialogue:\\n{dialogue}\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        summarization_zero_shot_prompt = f\"\"\"Summarize the following Dialogue in maximum two sentences, mentioning character's information\\n\\nDialogue:\\n{dialogue}:\n",
    "        \"\"\"\n",
    "    return summarization_zero_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following Dialogue in maximum two sentences, mentioning character's information\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_zero_shot_prompt(dialogue=dataset[\"test\"][0][\"dialogue\"], prompt_index=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_shot_prompt(dialogue: str, example_index: int, prompt_index: int) -> str:\n",
    "\n",
    "    example_dialogue = dataset[\"train\"][example_index][\"dialogue\"]\n",
    "    example_summary = dataset[\"train\"][example_index][\"summary\"]\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        summarization_one_shot_prompt = f\"\"\"Summarize the following Dialogue\\n\\nDialogue:\\n{example_dialogue}\\n\\nSummary:\\n{example_summary}\\n\\n-----\\n\\nDialogue:\\n{dialogue}\\n\\nSummary:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        summarization_one_shot_prompt = f\"\"\"Generate a concise summary of the following Dialogue\\n\\nDialogue:\\n{example_dialogue}\\n\\nSummary:\\n{example_summary}\\n\\n-----\\n\\nDialogue:\\n{dialogue}\\n\\nSummary:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        summarization_one_shot_prompt = f\"\"\"Summarize the following Dialogue in maximum two sentences, mentioning character's information\\n\\nDialogue:\\n{example_dialogue}\\n\\nSummary:\\n{example_summary}\\n\\n-----\\n\\nDialogue:\\n{dialogue}\\n\\nSummary:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    return summarization_one_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following Dialogue in maximum two sentences, mentioning character's information\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Excuse me, did you see a set of keys?\n",
      "#Person2#: What kind of keys?\n",
      "#Person1#: Five keys and a small foot ornament.\n",
      "#Person2#: What a shame! I didn't see them.\n",
      "#Person1#: Well, can you help me look for it? That's my first time here.\n",
      "#Person2#: Sure. It's my pleasure. I'd like to help you look for the missing keys.\n",
      "#Person1#: It's very kind of you.\n",
      "#Person2#: It's not a big deal.Hey, I found them.\n",
      "#Person1#: Oh, thank God! I don't know how to thank you, guys.\n",
      "#Person2#: You're welcome.\n",
      "\n",
      "Summary:\n",
      "#Person1#'s looking for a set of keys and asks for #Person2#'s help to find them.\n",
      "\n",
      "-----\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "\n",
      "Summary:\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_one_shot_prompt(dialogue=dataset[\"test\"][0][\"dialogue\"], example_index=2, prompt_index=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(dialogue: str, num_shots: int, prompt_index: int) -> str:\n",
    "\n",
    "    indices = random.sample(range(TRAINING_DATA_COUNT), num_shots)\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        summarization_few_shot_prompt = f\"\"\"Summarize the following Dialogue\"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        summarization_few_shot_prompt = f\"\"\"Generate a concise summary of the following Dialogue \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        summarization_few_shot_prompt = f\"\"\"Summarize the following Dialogue in maximum two sentences, mentioning character's information\"\"\"\n",
    "    for example_index in indices:\n",
    "        example_dialogue = dataset[\"train\"][example_index][\"dialogue\"]\n",
    "        example_summary = dataset[\"train\"][example_index][\"summary\"]\n",
    "        summarization_few_shot_prompt += f\"\\n\\nDialogue:\\n{example_dialogue}\\n\\nSummary:\\n{example_summary}\\n\\n-----\"\n",
    "\n",
    "    summarization_few_shot_prompt += f\"\\n\\nDialogue:\\n{dialogue}\\n\\nSummary:\\n\"\n",
    "\n",
    "    return summarization_few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a concise summary of the following Dialogue \n",
      "\n",
      "Dialogue:\n",
      "#Person1#: This is a wonderful pie. Is it homemade?\n",
      "#Person2#: It is, but I didn't make it. Jack did.\n",
      "#Person1#: I didn't know your husband cooked.\n",
      "#Person2#: Every week he makes something wonderful. He makes great fresh bread. Sometimes we give some to our neighbors.\n",
      "#Person1#: What else does your amazing husband do?\n",
      "#Person2#: He makes dinner every night.\n",
      "#Person1#: Really? I don't even know how to fry an egg.\n",
      "#Person2#: Jack even does the washing. I spend longer hours traveling from my home to my office and spend fewer hours at home. So he doesn't mind.\n",
      "#Person1#: Yes, our company is a little far from your home. Who does the cleaning?\n",
      "#Person2#: We both do. That way it only takes a small part of Saturday.\n",
      "\n",
      "Summary:\n",
      "#Person2# tells #Person1# that her husband makes something delicious every week, and makes dinner every night. #Person2# and her husband both do the cleaning.\n",
      "\n",
      "-----\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Hi, Albert. You know, John won first place during the chess competition and we've been asked to organize a party for him.\n",
      "#Person2#: Yeah, sure. It's about time we started to prepare it.\n",
      "#Person1#: Exactly. And when is the best time to hold it?\n",
      "#Person2#: Well, John will leave for Boston next Tuesday.\n",
      "#Person1#: So what about 2 days before he leaves on May thirteenth? That's a Sunday.\n",
      "#Person2#: Sounds nice.\n",
      "#Person1#: What about the place, at school or at a restaurant?\n",
      "#Person2#: I think it'll be expensive if we hold it at a restaurant. John said his grandparents welcome us to their big house.\n",
      "#Person1#: Great. And then, we ought to be thinking about invitations. Who must we invite?\n",
      "#Person2#: Well, John's chess coach.\n",
      "#Person1#: And John's parents?\n",
      "#Person2#: Yes. Besides, we'll invite at least 5 teachers and 20 students.\n",
      "#Person1#: OK. By the way, what gift will you give John?\n",
      "#Person2#: A book or a pen. What about you?\n",
      "#Person1#: Well, I will buy a dictionary for him. I heard him say that he needed a good one.\n",
      "#Person2#: Yeah, that's a good idea.\n",
      "\n",
      "Summary:\n",
      "#Person1# and Albert will organize a party for John for his winning first place during the chess competition. They are going to invite some people to John's grandparent's house to celebrate it.\n",
      "\n",
      "-----\n",
      "\n",
      "Dialogue:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_few_shot_prompt(dialogue=dataset[\"test\"][0][\"dialogue\"], num_shots=2, prompt_index=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human/Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def create_summarization_model_result(num_test_examples: int, output_csv_file: str, random_sample: bool = False) -> pd.DataFrame:\n",
    "    if random_sample:\n",
    "        test_examples_indices = random.sample(range(TEST_DATA_COUNT), num_test_examples)\n",
    "    else:\n",
    "        test_examples_indices = range(num_test_examples)\n",
    "\n",
    "    test_indices, test_dialogues, test_summaries = [],[],[]\n",
    "    zero_shot_prediction_summaries_1, zero_shot_prediction_summaries_2, zero_shot_prediction_summaries_3 = [],[],[]\n",
    "    one_shot_prediction_summaries_1, one_shot_prediction_summaries_2, one_shot_prediction_summaries_3 = [],[],[]\n",
    "    few_shot_prediction_summaries_1, few_shot_prediction_summaries_2, few_shot_prediction_summaries_3 = [],[],[]\n",
    "\n",
    "    for test_index in tqdm(test_examples_indices):\n",
    "        test_dialogue = dataset[\"test\"][test_index][\"dialogue\"]\n",
    "        test_summary = dataset[\"test\"][test_index][\"summary\"]\n",
    "        test_indices.append(test_index)\n",
    "        test_dialogues.append(test_dialogue)\n",
    "        test_summaries.append(test_summary)\n",
    "\n",
    "        for prompt_index in range(1,4):\n",
    "            zero_shot_prompt = create_zero_shot_prompt(dialogue = test_dialogue, prompt_index = prompt_index)\n",
    "            zero_shot_output = generate_llm_prediction(zero_shot_prompt)\n",
    "            one_shot_prompt = create_one_shot_prompt(dialogue = test_dialogue, example_index=prompt_index, prompt_index = prompt_index)\n",
    "            one_shot_output = generate_llm_prediction(one_shot_prompt)\n",
    "            few_shot_prompt = create_few_shot_prompt(dialogue = test_dialogue, num_shots=3, prompt_index = prompt_index)\n",
    "            few_shot_output = generate_llm_prediction(few_shot_prompt)\n",
    "\n",
    "            if prompt_index == 1:\n",
    "                zero_shot_prediction_summaries_1.append(zero_shot_output)\n",
    "                one_shot_prediction_summaries_1.append(one_shot_output)\n",
    "                few_shot_prediction_summaries_1.append(few_shot_output)\n",
    "            elif prompt_index == 2:\n",
    "                zero_shot_prediction_summaries_2.append(zero_shot_output)\n",
    "                one_shot_prediction_summaries_2.append(one_shot_output)\n",
    "                few_shot_prediction_summaries_2.append(few_shot_output)\n",
    "            else:\n",
    "                zero_shot_prediction_summaries_3.append(zero_shot_output)\n",
    "                one_shot_prediction_summaries_3.append(one_shot_output)\n",
    "                few_shot_prediction_summaries_3.append(few_shot_output)\n",
    "\n",
    "    df = pd.DataFrame({'Index':test_indices,'Dialogue':test_dialogues,'Gold Summary':test_summaries,\n",
    "                       'Zero_Shot_Pred_1':zero_shot_prediction_summaries_1,'Zero_Shot_Pred_2':zero_shot_prediction_summaries_2,'Zero_Shot_Pred_3':zero_shot_prediction_summaries_3,\n",
    "                       'One_Shot_Pred_1':one_shot_prediction_summaries_1,'One_Shot_Pred_2':one_shot_prediction_summaries_2,'One_Shot_Pred_3':one_shot_prediction_summaries_3,\n",
    "                       'Few_Shot_Pred_1':few_shot_prediction_summaries_1,'Few_Shot_Pred_2':few_shot_prediction_summaries_2,'Few_Shot_Pred_3':few_shot_prediction_summaries_3,\n",
    "                      })\n",
    "    df.to_csv(output_csv_file,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                               | 0/5 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:34<00:00,  6.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Gold Summary</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1106</td>\n",
       "      <td>#Person1#: Good evening. How many people of your party?\\n#Person2#: Three. Two adults and one kid.\\n#Person1#: For buffet?\\n#Person2#: Yes. How much do you charge for it?\\n#Person1#: Thirty for each adult, twenty each kid.\\n#Person2#: I see. Where can I get the food?\\n#Person1#: Please go to the tables over there for cold dishes and vegetables. The hot dishes are on the other side.\\n#Person2#: Do I need to pay extra charges for drinks like cola and juice?\\n#Person1#: Not for soft drinks. But we charge ten yuan for each alcohol order.</td>\n",
       "      <td>#Person2# tells #Person1# the charge policy at #Person2#'s buffet.</td>\n",
       "      <td>The party is going to be a great time.</td>\n",
       "      <td>The price is ten yuan.</td>\n",
       "      <td>The party is going to be a great evening.</td>\n",
       "      <td>The party is going to be a party.</td>\n",
       "      <td>The party is going to be a great evening.</td>\n",
       "      <td>The party is going to be a party.</td>\n",
       "      <td>The party is going to be a great evening.</td>\n",
       "      <td>The party is going to be a great evening.</td>\n",
       "      <td>The party is going to be a party.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413</td>\n",
       "      <td>#Person1#: Good morning. How can I help you?\\n#Person2#: I'd like to open a new account.\\n#Person1#: Have you filled out an application form?\\n#Person2#: Yes. And I've brought some documents along with me, too. Do you need to see my passport?\\n#Person1#: Yes. I'll just have my assistant look over these quickly and then we'll move on to the next step. Did you want to open up a checking account and a savings account?\\n#Person2#: Yes. Does the checking account come with a debit card?\\n#Person1#: Yes. Actually, both accounts come with cards that you can use in ATM machines, so that you won't have to come in to the bank to make a transaction.\\n#Person2#: That's very convenient.\\n#Person1#: It is. Our customers really like it. Do you have any other questions about your new accounts?\\n#Person2#: Yes. What's the maximum amount that you are allowed to have in an overdraft?\\n#Person1#: The maximum is $ 1000.\\n#Person2#: Is there a penalty for having an overdraft?\\n#Person1#: Yes, but it's not much. You just have to pay 1 % interest on the account. It's much lower rate than any of our loans and it's much better than owing money to most credit cards.\\n#Person2#: That's true. Is everything alright with my documents?\\n#Person1#: They're all in order. If you just sign your name here, you'll receive your cards and pin numbers in the mail in about three weeks.\\n#Person2#: Thank you very much.\\n#Person1#: You're welcome.</td>\n",
       "      <td>#Person1# helps #Person2# to open a new account. #Person1# answers #Person2#'s questions about the debit card, the maximum amount in an overdraft, and the penalty for having an overdraft.</td>\n",
       "      <td>You're welcome.</td>\n",
       "      <td>You're welcome.</td>\n",
       "      <td>The bank has a new account.</td>\n",
       "      <td>You're welcome.</td>\n",
       "      <td>#Person1#'s looking for a new account.</td>\n",
       "      <td>#Person1#: I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear</td>\n",
       "      <td>#Person1#: I'd like to open a new account. I've brought some documents along with me. I'll have my assistant look over these quickly and then we'll move on to the next step. Did you want to open up a checking account and a savings account?</td>\n",
       "      <td>How can I help you?</td>\n",
       "      <td>You're welcome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378</td>\n",
       "      <td>#Person1#: It's time for desserts! Are you still hungry?\\n#Person2#: I've always got room for something sweet!\\n#Person1#: what are you going to try first?\\n#Person2#: I've never tried traditional Greek yogurt, so I want to try that first.\\n#Person1#: do they serve the yogurt with anything?\\n#Person2#: I believe they add locally produced honey to it.\\n#Person1#: that sounds good. I'm going to start with an Italian tiramisu.\\n#Person2#: do you want to try some of my yogurt. It's a favorite everyday dessert in Greece.\\n#Person1#: ok. Mmm.\\n#Person2#: what do you think? How does it taste?\\n#Person1#: it's nice, but it's rather plain. Do you want to try my tiramisu?\\n#Person2#: sure. I'll just have a bite.\\n#Person1#: what do you think? Does it taste good?\\n#Person2#: it's absolutely delicious! That is the best tiramisu I've ever had!\\n#Person1#: I'm glad you like it. I don't care for it. Why don't you finish my tiramisu so that I can try one of those fried bananas?\\n#Person2#: ok. I've had one of those before. They're really sweet and crunchy.\\n#Person1#: do you know where they are from.\\n#Person2#: I believe they are a local delicacy in the South.\\n#Person1#: do you want me to get you one, too?\\n#Person2#: yeah, why not? We've already pigged out as it is!\\n#Person1#: ok, I'll be back with two fried bananas in a few minutes. Wait for me here!</td>\n",
       "      <td>#Person2# has traditional Greek yogurt, which #Person1# thinks rather plain. #Person1# has an Italian tiramisu, which #Person2# thinks delicious. #Person1# goes and gets both of them a fried banana.</td>\n",
       "      <td>Person1#: I'm going to try some of my tiramisu. I'm going to try some Italian tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu.</td>\n",
       "      <td>Person1#: I'm going to try some of my tiramisu.</td>\n",
       "      <td>Person1#: I'm going to try some of my tiramisu.</td>\n",
       "      <td>The desserts are coming up.</td>\n",
       "      <td>Person1#: I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramis</td>\n",
       "      <td>#Person1#: I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tir</td>\n",
       "      <td>The desserts are coming up.</td>\n",
       "      <td>The desserts are coming up.</td>\n",
       "      <td>The desserts are coming up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822</td>\n",
       "      <td>#Person1#: Is there a bus that'll go all the way to Sons from PHS?\\n#Person2#: Where is this Sons located?\\n#Person1#: The Sons on Fair Oaks and Orange Grove.\\n#Person2#: You're going to need to take two buses to get to that Sons.\\n#Person1#: Which buses will I have to take?\\n#Person2#: First, you need to get on the 268 going west.\\n#Person1#: Then what do I do?\\n#Person2#: You need to get off on Fair Oaks and Washington.\\n#Person1#: What's next?\\n#Person2#: Get on the 261, and it'll take you the rest of the way to Sons.\\n#Person1#: There's nothing else?\\n#Person2#: That's all there is to it.</td>\n",
       "      <td>#Person2# tells #Person1# the bus route to get to Sons.</td>\n",
       "      <td>You're going to need to take two buses to get to Sons.</td>\n",
       "      <td>You'll need to take two buses to get to Sons.</td>\n",
       "      <td>You're going to have to take two buses to get to Sons.</td>\n",
       "      <td>You'll need to take two buses to get to Sons.</td>\n",
       "      <td>You'll need to take two buses to get to Sons.</td>\n",
       "      <td>You're going to need to take two buses to get to Sons.</td>\n",
       "      <td>You're going to need to take two buses to get to Sons.</td>\n",
       "      <td>You'll need to take two buses to get to Sons.</td>\n",
       "      <td>You're going to need to take two buses to get to Sons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>787</td>\n",
       "      <td>#Person1#: Hey Sarah, are you all right? You look upset.\\n#Person2#: As a matter of fact, I am a bit upset. I just came out of a meeting and it didn't go very well.\\n#Person1#: What happened?\\n#Person2#: No one would listen to any of my suggestions. Instead, they just kept arguing with each other.\\n#Person1#: Who was chairing the meeting?\\n#Person2#: Bob.\\n#Person1#: Well, I can tell you from experience that Bob might come off a little strong sometimes.\\n#Person2#: That's exactly what happened! He kept interrupting everyone with his own suggestions and did not want to hear what others had to say. Then he expected everyone to agree with him.\\n#Person1#: What was the meeting about?\\n#Person2#: We were trying to come up with ideas to streamline the office's workflow to make it more efficient.\\n#Person1#: It's ironic that the meeting was anything but efficient.\\n#Person2#: Exactly. I had tons of ideas that I wanted to share, but they just wouldn't let me finish. What should I have done to get my point across?\\n#Person1#: You have to keep things short and sweet. When you get a chance to speak, try not to get into too many unnecessary details.\\n#Person2#: Short and sweet? But what if I have to explain something complicated?\\n#Person1#: You can always bring up the main points during the meeting and speak to those who are directly involved after the meeting. Not everyone needs to know all that information.\\n#Person2#: That's a good idea, I think I will try that at the next meeting.</td>\n",
       "      <td>Sarah is upset because Bob kept interrupting everyone else during a meeting, making it impossible to elaborate her ideas. #Person1# gives Sarah a useful tip to get her point across at the next meeting.</td>\n",
       "      <td>The meeting was a bit abysmal.</td>\n",
       "      <td>The meeting was a bit abysmal.</td>\n",
       "      <td>The meeting was not well.</td>\n",
       "      <td>The meeting was not well. It was a very short meeting.</td>\n",
       "      <td>The meeting was a bit abysmal. It was a meeting that everyone was arguing with.</td>\n",
       "      <td>The meeting was not well.</td>\n",
       "      <td>The meeting was not well. It was a very difficult meeting.</td>\n",
       "      <td>The meeting was not well. It was a very short meeting.</td>\n",
       "      <td>The meeting was not well.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  \\\n",
       "0   1106   \n",
       "1   1413   \n",
       "2    378   \n",
       "3    822   \n",
       "4    787   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Dialogue  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #Person1#: Good evening. How many people of your party?\\n#Person2#: Three. Two adults and one kid.\\n#Person1#: For buffet?\\n#Person2#: Yes. How much do you charge for it?\\n#Person1#: Thirty for each adult, twenty each kid.\\n#Person2#: I see. Where can I get the food?\\n#Person1#: Please go to the tables over there for cold dishes and vegetables. The hot dishes are on the other side.\\n#Person2#: Do I need to pay extra charges for drinks like cola and juice?\\n#Person1#: Not for soft drinks. But we charge ten yuan for each alcohol order.   \n",
       "1                                                                          #Person1#: Good morning. How can I help you?\\n#Person2#: I'd like to open a new account.\\n#Person1#: Have you filled out an application form?\\n#Person2#: Yes. And I've brought some documents along with me, too. Do you need to see my passport?\\n#Person1#: Yes. I'll just have my assistant look over these quickly and then we'll move on to the next step. Did you want to open up a checking account and a savings account?\\n#Person2#: Yes. Does the checking account come with a debit card?\\n#Person1#: Yes. Actually, both accounts come with cards that you can use in ATM machines, so that you won't have to come in to the bank to make a transaction.\\n#Person2#: That's very convenient.\\n#Person1#: It is. Our customers really like it. Do you have any other questions about your new accounts?\\n#Person2#: Yes. What's the maximum amount that you are allowed to have in an overdraft?\\n#Person1#: The maximum is $ 1000.\\n#Person2#: Is there a penalty for having an overdraft?\\n#Person1#: Yes, but it's not much. You just have to pay 1 % interest on the account. It's much lower rate than any of our loans and it's much better than owing money to most credit cards.\\n#Person2#: That's true. Is everything alright with my documents?\\n#Person1#: They're all in order. If you just sign your name here, you'll receive your cards and pin numbers in the mail in about three weeks.\\n#Person2#: Thank you very much.\\n#Person1#: You're welcome.   \n",
       "2                                                                                                                                           #Person1#: It's time for desserts! Are you still hungry?\\n#Person2#: I've always got room for something sweet!\\n#Person1#: what are you going to try first?\\n#Person2#: I've never tried traditional Greek yogurt, so I want to try that first.\\n#Person1#: do they serve the yogurt with anything?\\n#Person2#: I believe they add locally produced honey to it.\\n#Person1#: that sounds good. I'm going to start with an Italian tiramisu.\\n#Person2#: do you want to try some of my yogurt. It's a favorite everyday dessert in Greece.\\n#Person1#: ok. Mmm.\\n#Person2#: what do you think? How does it taste?\\n#Person1#: it's nice, but it's rather plain. Do you want to try my tiramisu?\\n#Person2#: sure. I'll just have a bite.\\n#Person1#: what do you think? Does it taste good?\\n#Person2#: it's absolutely delicious! That is the best tiramisu I've ever had!\\n#Person1#: I'm glad you like it. I don't care for it. Why don't you finish my tiramisu so that I can try one of those fried bananas?\\n#Person2#: ok. I've had one of those before. They're really sweet and crunchy.\\n#Person1#: do you know where they are from.\\n#Person2#: I believe they are a local delicacy in the South.\\n#Person1#: do you want me to get you one, too?\\n#Person2#: yeah, why not? We've already pigged out as it is!\\n#Person1#: ok, I'll be back with two fried bananas in a few minutes. Wait for me here!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #Person1#: Is there a bus that'll go all the way to Sons from PHS?\\n#Person2#: Where is this Sons located?\\n#Person1#: The Sons on Fair Oaks and Orange Grove.\\n#Person2#: You're going to need to take two buses to get to that Sons.\\n#Person1#: Which buses will I have to take?\\n#Person2#: First, you need to get on the 268 going west.\\n#Person1#: Then what do I do?\\n#Person2#: You need to get off on Fair Oaks and Washington.\\n#Person1#: What's next?\\n#Person2#: Get on the 261, and it'll take you the rest of the way to Sons.\\n#Person1#: There's nothing else?\\n#Person2#: That's all there is to it.   \n",
       "4  #Person1#: Hey Sarah, are you all right? You look upset.\\n#Person2#: As a matter of fact, I am a bit upset. I just came out of a meeting and it didn't go very well.\\n#Person1#: What happened?\\n#Person2#: No one would listen to any of my suggestions. Instead, they just kept arguing with each other.\\n#Person1#: Who was chairing the meeting?\\n#Person2#: Bob.\\n#Person1#: Well, I can tell you from experience that Bob might come off a little strong sometimes.\\n#Person2#: That's exactly what happened! He kept interrupting everyone with his own suggestions and did not want to hear what others had to say. Then he expected everyone to agree with him.\\n#Person1#: What was the meeting about?\\n#Person2#: We were trying to come up with ideas to streamline the office's workflow to make it more efficient.\\n#Person1#: It's ironic that the meeting was anything but efficient.\\n#Person2#: Exactly. I had tons of ideas that I wanted to share, but they just wouldn't let me finish. What should I have done to get my point across?\\n#Person1#: You have to keep things short and sweet. When you get a chance to speak, try not to get into too many unnecessary details.\\n#Person2#: Short and sweet? But what if I have to explain something complicated?\\n#Person1#: You can always bring up the main points during the meeting and speak to those who are directly involved after the meeting. Not everyone needs to know all that information.\\n#Person2#: That's a good idea, I think I will try that at the next meeting.   \n",
       "\n",
       "                                                                                                                                                                                                Gold Summary  \\\n",
       "0                                                                                                                                         #Person2# tells #Person1# the charge policy at #Person2#'s buffet.   \n",
       "1                #Person1# helps #Person2# to open a new account. #Person1# answers #Person2#'s questions about the debit card, the maximum amount in an overdraft, and the penalty for having an overdraft.   \n",
       "2     #Person2# has traditional Greek yogurt, which #Person1# thinks rather plain. #Person1# has an Italian tiramisu, which #Person2# thinks delicious. #Person1# goes and gets both of them a fried banana.   \n",
       "3                                                                                                                                                    #Person2# tells #Person1# the bus route to get to Sons.   \n",
       "4  Sarah is upset because Bob kept interrupting everyone else during a meeting, making it impossible to elaborate her ideas. #Person1# gives Sarah a useful tip to get her point across at the next meeting.   \n",
       "\n",
       "                                                                                                                                                      Zero_Shot_Pred_1  \\\n",
       "0                                                                                                                               The party is going to be a great time.   \n",
       "1                                                                                                                                                      You're welcome.   \n",
       "2  Person1#: I'm going to try some of my tiramisu. I'm going to try some Italian tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu.   \n",
       "3                                                                                                               You're going to need to take two buses to get to Sons.   \n",
       "4                                                                                                                                       The meeting was a bit abysmal.   \n",
       "\n",
       "                                  Zero_Shot_Pred_2  \\\n",
       "0                           The price is ten yuan.   \n",
       "1                                  You're welcome.   \n",
       "2  Person1#: I'm going to try some of my tiramisu.   \n",
       "3    You'll need to take two buses to get to Sons.   \n",
       "4                   The meeting was a bit abysmal.   \n",
       "\n",
       "                                         Zero_Shot_Pred_3  \\\n",
       "0               The party is going to be a great evening.   \n",
       "1                             The bank has a new account.   \n",
       "2         Person1#: I'm going to try some of my tiramisu.   \n",
       "3  You're going to have to take two buses to get to Sons.   \n",
       "4                               The meeting was not well.   \n",
       "\n",
       "                                          One_Shot_Pred_1  \\\n",
       "0                       The party is going to be a party.   \n",
       "1                                         You're welcome.   \n",
       "2                             The desserts are coming up.   \n",
       "3           You'll need to take two buses to get to Sons.   \n",
       "4  The meeting was not well. It was a very short meeting.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                     One_Shot_Pred_2  \\\n",
       "0                                                                                                                                                                                                                                          The party is going to be a great evening.   \n",
       "1                                                                                                                                                                                                                                            #Person1#'s looking for a new account.    \n",
       "2  Person1#: I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramis   \n",
       "3                                                                                                                                                                                                                                      You'll need to take two buses to get to Sons.   \n",
       "4                                                                                                                                                                                                    The meeting was a bit abysmal. It was a meeting that everyone was arguing with.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        One_Shot_Pred_3  \\\n",
       "0                                                                                                                                                                                                                                                                     The party is going to be a party.   \n",
       "1  #Person1#: I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear that. I'm sorry to hear   \n",
       "2                        #Person1#: I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tiramisu. I'm going to try some of my tir   \n",
       "3                                                                                                                                                                                                                                                You're going to need to take two buses to get to Sons.   \n",
       "4                                                                                                                                                                                                                                                                             The meeting was not well.   \n",
       "\n",
       "                                                                                                                                                                                                                                   Few_Shot_Pred_1  \\\n",
       "0                                                                                                                                                                                                        The party is going to be a great evening.   \n",
       "1  #Person1#: I'd like to open a new account. I've brought some documents along with me. I'll have my assistant look over these quickly and then we'll move on to the next step. Did you want to open up a checking account and a savings account?   \n",
       "2                                                                                                                                                                                                                      The desserts are coming up.   \n",
       "3                                                                                                                                                                                          You're going to need to take two buses to get to Sons.    \n",
       "4                                                                                                                                                                                       The meeting was not well. It was a very difficult meeting.   \n",
       "\n",
       "                                          Few_Shot_Pred_2  \\\n",
       "0               The party is going to be a great evening.   \n",
       "1                                    How can I help you?    \n",
       "2                             The desserts are coming up.   \n",
       "3          You'll need to take two buses to get to Sons.    \n",
       "4  The meeting was not well. It was a very short meeting.   \n",
       "\n",
       "                                           Few_Shot_Pred_3  \n",
       "0                        The party is going to be a party.  \n",
       "1                                          You're welcome.  \n",
       "2                              The desserts are coming up.  \n",
       "3  You're going to need to take two buses to get to Sons.   \n",
       "4                                The meeting was not well.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_summarization_model_result(num_test_examples = 5, output_csv_file = 'Summarization_Evaluation_Sample_5.csv', random_sample = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Analysis:\n",
    "\n",
    "1. Current Model summarization results especially with zero & one shot do not perform well. The improvement in the few shot results demonstrates model's in-context learning capabilities \n",
    "2. Since human evaluation takes time, we also analyze the quantitative results in the next section to get a better understanding of the entire test set\n",
    "3. The results can be improvised by\n",
    "   - Experimenting with other prompts\n",
    "   - Experimenting with different configuration parameters of the model (e.g: do_sample=True for different decoding strategies)\n",
    "   - Perform fine-tuning on data\n",
    "   - Using larger parameters model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric/Quantitative Evaluation\n",
    "\n",
    "We will use **[ROUGE](https://https://huggingface.co/spaces/evaluate-metric/rouge)** metric for our evaluation which is the most common metric used in Summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in ./flan_env/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./flan_env/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./flan_env/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in ./flan_env/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./flan_env/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./flan_env/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./flan_env/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./flan_env/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./flan_env/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./flan_env/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./flan_env/lib/python3.10/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in ./flan_env/lib/python3.10/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: responses<0.19 in ./flan_env/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in ./flan_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./flan_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./flan_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in ./flan_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./flan_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./flan_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./flan_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./flan_env/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./flan_env/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./flan_env/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./flan_env/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in ./flan_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in ./flan_env/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./flan_env/lib/python3.10/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in ./flan_env/lib/python3.10/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./flan_env/lib/python3.10/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in ./flan_env/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in ./flan_env/lib/python3.10/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./flan_env/lib/python3.10/site-packages (from nltk->rouge-score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./flan_env/lib/python3.10/site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./flan_env/lib/python3.10/site-packages (from nltk->rouge-score) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric/Quantitative Evaluation\n",
    "\n",
    "We will use **[ROUGE](https://https://huggingface.co/spaces/evaluate-metric/rouge)** metric for our evaluation which is the most common metric used in Summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e779fe90fcbd4eb1aeb6d09847065279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(predictions,gold_answers):\n",
    "    results = rouge.compute(predictions=predictions,\n",
    "                            references=gold_answers,\n",
    "                            use_stemmer = True,\n",
    "                            use_aggregator=True)\n",
    "    return results\n",
    "\n",
    "def create_rouge_eval_result(df: pd.DataFrame, output_csv_file: str, gold_column: str) -> pd.DataFrame:\n",
    "    \n",
    "    gold_answers = df[gold_column].tolist()\n",
    "    zero_shot_prediction_answers_1, zero_shot_prediction_answers_2, zero_shot_prediction_answers_3 = df['Zero_Shot_Pred_1'].tolist(), df['Zero_Shot_Pred_2'].tolist(), df['Zero_Shot_Pred_3'].tolist()\n",
    "    one_shot_prediction_answers_1, one_shot_prediction_answers_2, one_shot_prediction_answers_3 = df['One_Shot_Pred_1'].tolist(), df['One_Shot_Pred_2'].tolist(), df['One_Shot_Pred_3'].tolist()\n",
    "    few_shot_prediction_answers_1, few_shot_prediction_answers_2, few_shot_prediction_answers_3 = df['Few_Shot_Pred_1'].tolist(), df['Few_Shot_Pred_2'].tolist(), df['Few_Shot_Pred_3'].tolist()\n",
    "    \n",
    "    columns = ['rouge1', 'rouge2','rougeL', 'rougeLSum']\n",
    "    rows = ['Zero_Shot_Prompt_1', 'Zero_Shot_Prompt_2', 'Zero_Shot_Prompt_3', 'One_Shot_Prompt_1', 'One_Shot_Prompt_2', 'One_Shot_Prompt_3','Few_Shot_Prompt_1', 'Few_Shot_Prompt_2', 'Few_Shot_Prompt_3']\n",
    "    df_res = pd.DataFrame(index=rows, columns=columns)\n",
    "    \n",
    "    df_res.loc['Zero_Shot_Prompt_1'] = list(compute_rouge(zero_shot_prediction_answers_1,gold_answers).values())\n",
    "    df_res.loc['Zero_Shot_Prompt_2'] = list(compute_rouge(zero_shot_prediction_answers_2,gold_answers).values())\n",
    "    df_res.loc['Zero_Shot_Prompt_3'] = list(compute_rouge(zero_shot_prediction_answers_3,gold_answers).values())\n",
    "    \n",
    "    df_res.loc['One_Shot_Prompt_1'] = list(compute_rouge(one_shot_prediction_answers_1,gold_answers).values())\n",
    "    df_res.loc['One_Shot_Prompt_2'] = list(compute_rouge(one_shot_prediction_answers_2,gold_answers).values())\n",
    "    df_res.loc['One_Shot_Prompt_3'] = list(compute_rouge(one_shot_prediction_answers_3,gold_answers).values())\n",
    "    \n",
    "    df_res.loc['Few_Shot_Prompt_1'] = list(compute_rouge(few_shot_prediction_answers_1,gold_answers).values())\n",
    "    df_res.loc['Few_Shot_Prompt_2'] = list(compute_rouge(few_shot_prediction_answers_2,gold_answers).values())\n",
    "    df_res.loc['Few_Shot_Prompt_3'] = list(compute_rouge(few_shot_prediction_answers_3,gold_answers).values())\n",
    "    \n",
    "    df_res.to_csv(output_csv_file)\n",
    "    return df_res\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [12:30<00:00,  7.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Gold Summary</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855</td>\n",
       "      <td>#Person1#: Tomorrow is Mike's birthday. I have just received the invitation to his party. Did Mike invite you, too?\\n#Person2#: Yes. I received his invitation this morning. But he didn't tell me what time the party will begin.\\n#Person1#: I'll ring him up and ask him about it. How will you go to his party?\\n#Person2#: I'll drive to his party after work. Would you like to take my car there?\\n#Person1#: I would be glad to. Thank you.</td>\n",
       "      <td>#Person1# and #Person2# are going to Mike's birthday party tomorrow.</td>\n",
       "      <td>Mike invited you to his party tomorrow.</td>\n",
       "      <td>Mike invited you to his party tomorrow.</td>\n",
       "      <td>Mike invited him to his party.</td>\n",
       "      <td>Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "      <td>Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "      <td>Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "      <td>Mike invited him to his party tomorrow. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "      <td>Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "      <td>Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995</td>\n",
       "      <td>#Person1#: I want to make sure my son receives this letter. It has an important certificate in it.\\n#Person2#: You can send it either by certified mail or registered mail. If you only want to make sure it is received, send it by certified mail. It's less expensive.\\n#Person1#: OK. How about this package?\\n#Person2#: What's in it?\\n#Person1#: A watch.\\n#Person2#: You should insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.</td>\n",
       "      <td>#Person1# will send a certificate by certified mail and a watch by registered mail.</td>\n",
       "      <td>You can send it by registered mail.</td>\n",
       "      <td>You can send it by registered mail.</td>\n",
       "      <td>You should send the watch to the recipient.</td>\n",
       "      <td>Send the package to your son.</td>\n",
       "      <td>You can send a certificate to your son.</td>\n",
       "      <td>Send the package to the person who is sending the package.</td>\n",
       "      <td>Send the package to your son.</td>\n",
       "      <td>You can send a certificate to your son.</td>\n",
       "      <td>You can send a package to your son.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>935</td>\n",
       "      <td>#Person1#: Thank you for organizing this great baby shower for me! I'Ve always been to baby showers but never actually had one held for me! Let's get started!\\n#Person2#: Ok, let's start opening some presents!\\n#Person1#: Oh look! What a great little bib for the baby! This will definitely come in handy! Oh wow, you also got me a stroller! That's so great! Thank you!\\n#Person2#: This next one is from Betty.\\n#Person1#: A highchair and car seat! Wow Betty, thank you so much! I really appreciate it!\\n#Person2#: One more from Carla.\\n#Person1#: A playpen and crib! Thanks Carla! This is just what I needed!\\n#Person2#: OK, that's all of them. No more gifts. Now who wants to guess when the baby is due?\\n#Person1#: Umm. I think my water just broke! Get me to a hospital!</td>\n",
       "      <td>#Person2# organized a great baby shower for #Person1#. #Person1# receives many gifts. #Person1#'s water broke.</td>\n",
       "      <td>The baby shower is going to be a great one!</td>\n",
       "      <td>The baby shower is going to be a great one!</td>\n",
       "      <td>The baby is due to be born in the hospital.</td>\n",
       "      <td>The baby shower is going to be a great one!</td>\n",
       "      <td>#Person1#: I'm going to get a baby shower. I'm going to get a baby shower.</td>\n",
       "      <td>#Person1#: I'm going to get a baby shower for my baby.</td>\n",
       "      <td>#Person1#: Thank you for organizing this great baby shower for me!</td>\n",
       "      <td>#Person1#: I'm going to get a baby shower. I'm going to get a baby shower.</td>\n",
       "      <td>#Person1#: I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1457</td>\n",
       "      <td>#Person1#: Hi. What's up? \\n#Person2#: Nothing much. What's new with you? \\n#Person1#: Not too much. I've been pretty busy. \\n#Person2#: Me too. Seems like all I do is eat and sleep. \\n#Person1#: Gotta go. Call me tonight. \\n#Person2#: Okay. Check you later.</td>\n",
       "      <td>#Person1# is busy while #Person2# is flexible.</td>\n",
       "      <td>I'm sorry.</td>\n",
       "      <td>Person1#: I'm not sure what to do.</td>\n",
       "      <td>Person1#: I'm not sure what to do.</td>\n",
       "      <td>The new person is coming to her.</td>\n",
       "      <td>Person1#: Hi, I'm sorry. I'm not sure what to do. I'm going to call you tonight.</td>\n",
       "      <td>Person1#: Hi, I'm sorry. I'm not sure what to do. I'm going to call you tonight.</td>\n",
       "      <td></td>\n",
       "      <td>Person1#: Hi, I'm sorry. I'm not sure what to do tonight.</td>\n",
       "      <td>The new person is coming to her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>446</td>\n",
       "      <td>#Person1#: Hi, Dan, I'm calling to check on that order of 100 computers were the tenth of September. However, it has been delayed for 2 days.\\n#Person2#: Yes, I know. I mean to call you and tell you that the factory is short of hands at the moment. They say they can get the order to you by the eighteenth.\\n#Person1#: Oh, that's too late. If you can give me Steve's phone number, I'll call him and tell him about this. Do you have his number handy?\\n#Person2#: Yes, it's 87506638.\\n#Person1#: Sorry, is that double 6 or double 3?\\n#Person2#: Double 6.\\n#Person1#: I suppose he can't really complain. Those computers are a bargain.\\n#Person2#: Exactly. A few days, it shouldn't make that much difference. Thanks for understanding, Darlene.\\n#Person1#: No problem.</td>\n",
       "      <td>Darlen calls Dan to check the delayed order of computers. Dan explains to her the reason for the delay. Darlene decides to talk to Steven.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "      <td>Dan is calling to check on the order of 100 computers. It has been delayed for 2 days. Steve will call him and tell him about it.</td>\n",
       "      <td>#Person1#: I'm calling to check on the order of 100 computers. It's delayed for 2 days. Steve will call him and tell him about it.</td>\n",
       "      <td>The order has been delayed for 2 days. Steve will call him and tell him about it.</td>\n",
       "      <td>The order has been delayed for 2 days.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  \\\n",
       "0    855   \n",
       "1    995   \n",
       "2    935   \n",
       "3   1457   \n",
       "4    446   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Dialogue  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                   #Person1#: Tomorrow is Mike's birthday. I have just received the invitation to his party. Did Mike invite you, too?\\n#Person2#: Yes. I received his invitation this morning. But he didn't tell me what time the party will begin.\\n#Person1#: I'll ring him up and ask him about it. How will you go to his party?\\n#Person2#: I'll drive to his party after work. Would you like to take my car there?\\n#Person1#: I would be glad to. Thank you.   \n",
       "1                                                                                                                                                                                                                                                                                          #Person1#: I want to make sure my son receives this letter. It has an important certificate in it.\\n#Person2#: You can send it either by certified mail or registered mail. If you only want to make sure it is received, send it by certified mail. It's less expensive.\\n#Person1#: OK. How about this package?\\n#Person2#: What's in it?\\n#Person1#: A watch.\\n#Person2#: You should insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.   \n",
       "2  #Person1#: Thank you for organizing this great baby shower for me! I'Ve always been to baby showers but never actually had one held for me! Let's get started!\\n#Person2#: Ok, let's start opening some presents!\\n#Person1#: Oh look! What a great little bib for the baby! This will definitely come in handy! Oh wow, you also got me a stroller! That's so great! Thank you!\\n#Person2#: This next one is from Betty.\\n#Person1#: A highchair and car seat! Wow Betty, thank you so much! I really appreciate it!\\n#Person2#: One more from Carla.\\n#Person1#: A playpen and crib! Thanks Carla! This is just what I needed!\\n#Person2#: OK, that's all of them. No more gifts. Now who wants to guess when the baby is due?\\n#Person1#: Umm. I think my water just broke! Get me to a hospital!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   #Person1#: Hi. What's up? \\n#Person2#: Nothing much. What's new with you? \\n#Person1#: Not too much. I've been pretty busy. \\n#Person2#: Me too. Seems like all I do is eat and sleep. \\n#Person1#: Gotta go. Call me tonight. \\n#Person2#: Okay. Check you later.    \n",
       "4           #Person1#: Hi, Dan, I'm calling to check on that order of 100 computers were the tenth of September. However, it has been delayed for 2 days.\\n#Person2#: Yes, I know. I mean to call you and tell you that the factory is short of hands at the moment. They say they can get the order to you by the eighteenth.\\n#Person1#: Oh, that's too late. If you can give me Steve's phone number, I'll call him and tell him about this. Do you have his number handy?\\n#Person2#: Yes, it's 87506638.\\n#Person1#: Sorry, is that double 6 or double 3?\\n#Person2#: Double 6.\\n#Person1#: I suppose he can't really complain. Those computers are a bargain.\\n#Person2#: Exactly. A few days, it shouldn't make that much difference. Thanks for understanding, Darlene.\\n#Person1#: No problem.   \n",
       "\n",
       "                                                                                                                                 Gold Summary  \\\n",
       "0                                                                        #Person1# and #Person2# are going to Mike's birthday party tomorrow.   \n",
       "1                                                         #Person1# will send a certificate by certified mail and a watch by registered mail.   \n",
       "2                              #Person2# organized a great baby shower for #Person1#. #Person1# receives many gifts. #Person1#'s water broke.   \n",
       "3                                                                                              #Person1# is busy while #Person2# is flexible.   \n",
       "4  Darlen calls Dan to check the delayed order of computers. Dan explains to her the reason for the delay. Darlene decides to talk to Steven.   \n",
       "\n",
       "                              Zero_Shot_Pred_1  \\\n",
       "0      Mike invited you to his party tomorrow.   \n",
       "1          You can send it by registered mail.   \n",
       "2  The baby shower is going to be a great one!   \n",
       "3                                   I'm sorry.   \n",
       "4       The order has been delayed for 2 days.   \n",
       "\n",
       "                              Zero_Shot_Pred_2  \\\n",
       "0      Mike invited you to his party tomorrow.   \n",
       "1          You can send it by registered mail.   \n",
       "2  The baby shower is going to be a great one!   \n",
       "3           Person1#: I'm not sure what to do.   \n",
       "4       The order has been delayed for 2 days.   \n",
       "\n",
       "                              Zero_Shot_Pred_3  \\\n",
       "0               Mike invited him to his party.   \n",
       "1  You should send the watch to the recipient.   \n",
       "2  The baby is due to be born in the hospital.   \n",
       "3           Person1#: I'm not sure what to do.   \n",
       "4       The order has been delayed for 2 days.   \n",
       "\n",
       "                                                                                                            One_Shot_Pred_1  \\\n",
       "0  Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.   \n",
       "1                                                                                             Send the package to your son.   \n",
       "2                                                                               The baby shower is going to be a great one!   \n",
       "3                                                                                          The new person is coming to her.   \n",
       "4                                                                                    The order has been delayed for 2 days.   \n",
       "\n",
       "                                                                                                            One_Shot_Pred_2  \\\n",
       "0  Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.   \n",
       "1                                                                                   You can send a certificate to your son.   \n",
       "2                                                #Person1#: I'm going to get a baby shower. I'm going to get a baby shower.   \n",
       "3                                          Person1#: Hi, I'm sorry. I'm not sure what to do. I'm going to call you tonight.   \n",
       "4                                                                                    The order has been delayed for 2 days.   \n",
       "\n",
       "                                                                                                                     One_Shot_Pred_3  \\\n",
       "0           Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.   \n",
       "1                                                                        Send the package to the person who is sending the package.    \n",
       "2                                                                             #Person1#: I'm going to get a baby shower for my baby.   \n",
       "3                                                   Person1#: Hi, I'm sorry. I'm not sure what to do. I'm going to call you tonight.   \n",
       "4  Dan is calling to check on the order of 100 computers. It has been delayed for 2 days. Steve will call him and tell him about it.   \n",
       "\n",
       "                                                                                                                      Few_Shot_Pred_1  \\\n",
       "0   Mike invited him to his party tomorrow. He didn't tell him what time the party will begin. He will drive to his party after work.   \n",
       "1                                                                                                       Send the package to your son.   \n",
       "2                                                                  #Person1#: Thank you for organizing this great baby shower for me!   \n",
       "3                                                                                                                                       \n",
       "4  #Person1#: I'm calling to check on the order of 100 computers. It's delayed for 2 days. Steve will call him and tell him about it.   \n",
       "\n",
       "                                                                                                            Few_Shot_Pred_2  \\\n",
       "0  Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.   \n",
       "1                                                                                   You can send a certificate to your son.   \n",
       "2                                                #Person1#: I'm going to get a baby shower. I'm going to get a baby shower.   \n",
       "3                                                                 Person1#: Hi, I'm sorry. I'm not sure what to do tonight.   \n",
       "4                                         The order has been delayed for 2 days. Steve will call him and tell him about it.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                               Few_Shot_Pred_3  \n",
       "0                                                                                                                                                                     Mike invited him to his party. He didn't tell him what time the party will begin. He will drive to his party after work.  \n",
       "1                                                                                                                                                                                                                                                          You can send a package to your son.  \n",
       "2  #Person1#: I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get a baby shower. I'm going to get  \n",
       "3                                                                                                                                                                                                                                                             The new person is coming to her.  \n",
       "4                                                                                                                                                                                                                                                       The order has been delayed for 2 days.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_summarization_model_result(num_test_examples = 100, output_csv_file = 'Summarization_Evaluation_100_samples.csv', random_sample = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_1</th>\n",
       "      <td>0.183994</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.160555</td>\n",
       "      <td>0.161329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_2</th>\n",
       "      <td>0.208274</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>0.182395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_3</th>\n",
       "      <td>0.223767</td>\n",
       "      <td>0.061977</td>\n",
       "      <td>0.193929</td>\n",
       "      <td>0.194391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_1</th>\n",
       "      <td>0.224383</td>\n",
       "      <td>0.068509</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.195347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_2</th>\n",
       "      <td>0.219647</td>\n",
       "      <td>0.060113</td>\n",
       "      <td>0.189187</td>\n",
       "      <td>0.189051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_3</th>\n",
       "      <td>0.22811</td>\n",
       "      <td>0.062997</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.199574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_1</th>\n",
       "      <td>0.209409</td>\n",
       "      <td>0.05746</td>\n",
       "      <td>0.180622</td>\n",
       "      <td>0.180401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_2</th>\n",
       "      <td>0.217498</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>0.190294</td>\n",
       "      <td>0.191047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_3</th>\n",
       "      <td>0.21155</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>0.184321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rouge1    rouge2    rougeL rougeLSum\n",
       "Zero_Shot_Prompt_1  0.183994  0.052109  0.160555  0.161329\n",
       "Zero_Shot_Prompt_2  0.208274  0.059867  0.181422  0.182395\n",
       "Zero_Shot_Prompt_3  0.223767  0.061977  0.193929  0.194391\n",
       "One_Shot_Prompt_1   0.224383  0.068509  0.194876  0.195347\n",
       "One_Shot_Prompt_2   0.219647  0.060113  0.189187  0.189051\n",
       "One_Shot_Prompt_3    0.22811  0.062997  0.200011  0.199574\n",
       "Few_Shot_Prompt_1   0.209409   0.05746  0.180622  0.180401\n",
       "Few_Shot_Prompt_2   0.217498  0.062132  0.190294  0.191047\n",
       "Few_Shot_Prompt_3    0.21155  0.057521  0.184962  0.184321"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = create_rouge_eval_result(df, output_csv_file = 'Summarization_Evaluation_100_samples_Metrics.csv', gold_column = 'Gold Summary') \n",
    "df_res.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Summary\n",
    "1. There is no substantial difference in the Rouge score in various methods\n",
    "2. The results can be improvised by\n",
    "   - Experimenting with other prompts\n",
    "   - Experimenting with different configuration parameters of the model (e.g: do_sample=True for different decoding strategies)\n",
    "   - Perform fine-tuning on data\n",
    "   - Using a larger parameters model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Verify if the Q&A task works.\n",
    "\n",
    "We will experiment with samples from SQuAD dataset for Q&A task. We will consider this as a **Generative QA** task\n",
    "\n",
    "SQuAD, short for Stanford Question Answering Dataset, is a dataset designed for training and evaluating question answering systems. It consists of real questions posed by humans on a set of Wikipedia articles, where the answer to each question is a specific span of text within the corresponding article. The dataset is widely used in the field of natural language processing (NLP) and serves as a benchmark for evaluating the performance of machine learning and artificial intelligence models in understanding and answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 130319\n",
      "Test dataset size: 11873\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset_name = \"rajpurkar/squad_v2\"\n",
    "dataset = datasets.load_dataset(dataset_name)\n",
    "\n",
    "TRAINING_DATA_COUNT = len(dataset['train'])\n",
    "TEST_DATA_COUNT = len(dataset['validation'])\n",
    "\n",
    "print(f\"Train dataset size: {TRAINING_DATA_COUNT}\")\n",
    "print(f\"Test dataset size: {TEST_DATA_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [269], 'text': ['in the late 1990s']},\n",
      " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born '\n",
      "            'September 4, 1981) is an American singer, songwriter, record '\n",
      "            'producer and actress. Born and raised in Houston, Texas, she '\n",
      "            'performed in various singing and dancing competitions as a child, '\n",
      "            'and rose to fame in the late 1990s as lead singer of R&B '\n",
      "            \"girl-group Destiny's Child. Managed by her father, Mathew \"\n",
      "            \"Knowles, the group became one of the world's best-selling girl \"\n",
      "            \"groups of all time. Their hiatus saw the release of Beyoncé's \"\n",
      "            'debut album, Dangerously in Love (2003), which established her as '\n",
      "            'a solo artist worldwide, earned five Grammy Awards and featured '\n",
      "            'the Billboard Hot 100 number-one singles \"Crazy in Love\" and '\n",
      "            '\"Baby Boy\".',\n",
      " 'id': '56be85543aeaaa14008c9063',\n",
      " 'question': 'When did Beyonce start becoming popular?',\n",
      " 'title': 'Beyoncé'}\n"
     ]
    }
   ],
   "source": [
    "# Sample Data\n",
    "from pprint import pprint \n",
    "sample_data = next(iter(dataset['train']))\n",
    "pprint(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset: datasets.Dataset, data_type: str) -> dict:\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for sample_data in dataset[data_type]:\n",
    "        contexts.append(sample_data.get('context',''))\n",
    "        questions.append(sample_data.get('question',''))\n",
    "        if 'answers' in sample_data and 'text' in sample_data['answers']:\n",
    "            answers.append(sample_data['answers']['text'])\n",
    "        else:\n",
    "            answers.append('')\n",
    "    return {'contexts':contexts, 'questions':questions, 'answers':answers}\n",
    "\n",
    "train_data = read_data(dataset,'train')\n",
    "valid_data = read_data(dataset,'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt(context: str, question: str, prompt_index: int) -> str:\n",
    "    if prompt_index == 1:\n",
    "        qa_zero_shot_prompt = f\"\"\"Given a Context and a Question, utilize the context to answer the question. Don't use any other information\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        qa_zero_shot_prompt = f\"\"\"Answer the given Question based on the provided Context. Don't use any other information\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        qa_zero_shot_prompt = f\"\"\"Given a Context and a Question, extract the relevant content from the context that answers the given question. Don't generate anything on your own. Return only the extracted content\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\n",
    "        \"\"\"\n",
    "    return qa_zero_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a Context and a Question, utilize the context to answer the question. Don't use any other information\n",
      "\n",
      "Context:\n",
      "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "\n",
      "Question:\n",
      "In what country is Normandy located?\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_zero_shot_prompt(context=dataset[\"validation\"][0][\"context\"], question=dataset[\"validation\"][0][\"question\"], prompt_index=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_shot_prompt(context: str, question: str, example_index: int, prompt_index: int) -> str:\n",
    "\n",
    "    example_context = dataset[\"train\"][example_index].get('context','')\n",
    "    example_question = dataset[\"train\"][example_index].get('question','')\n",
    "    if 'answers' in dataset[\"train\"][example_index] and 'text' in dataset[\"train\"][example_index]['answers']:\n",
    "        example_answer = dataset[\"train\"][example_index]['answers']['text'][0]\n",
    "    else:\n",
    "         example_answer = ''\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        qa_one_shot_prompt = f\"\"\"Given a Context and a Question, utilize the context to answer the question. Don't use any other information\\n\\nContext:\\n{example_context}\\n\\nQuestion:\\n{example_question}\\n\\nAnswer:\\n{example_answer}\\n\\n-----\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\n",
    "        \"\"\"\n",
    "    \n",
    "    elif prompt_index == 2:\n",
    "        qa_one_shot_prompt = f\"\"\"Answer the given Question based on the provided Context. Don't use any other information\\n\\nContext:\\n{example_context}\\n\\nQuestion:\\n{example_question}\\n\\nAnswer:\\n{example_answer}\\n\\n-----\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        qa_one_shot_prompt = f\"\"\"Given a Context and a Question, extract the relevant content from the context that answers the given question. Don't generate anything on your own. Return only the extracted content\\n\\nContext:\\n{example_context}\\n\\nQuestion:\\n{example_question}\\n\\nAnswer:\\n{example_answer}\\n\\n-----\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    return qa_one_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the given Question based on the provided Context. Don't use any other information\n",
      "\n",
      "Context:\n",
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "\n",
      "Question:\n",
      "When did Beyonce leave Destiny's Child and become a solo singer?\n",
      "\n",
      "Answer:\n",
      "2003\n",
      "\n",
      "-----\n",
      "\n",
      "Context:\n",
      "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "\n",
      "Question:\n",
      "In what country is Normandy located?\n",
      "\n",
      "Answer:\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_one_shot_prompt(context=dataset[\"validation\"][0][\"context\"], question=dataset[\"validation\"][0][\"question\"], example_index=2, prompt_index=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(context: str, question: str, num_shots: int, prompt_index: int) -> str:\n",
    "\n",
    "    indices = random.sample(range(TRAINING_DATA_COUNT), num_shots)\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        qa_few_shot_prompt = f\"\"\"Given a Context and a Question, utilize the context to answer the question. Don't use any other information\"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        qa_few_shot_prompt = f\"\"\"Answer the given Question based on the provided Context. Don't use any other information\"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        qa_few_shot_prompt = f\"\"\"Given a Context and a Question, extract the relevant content from the context that answers the given question. Don't generate anything on your own. Return only the extracted content\"\"\"\n",
    "    for example_index in indices:\n",
    "        example_context = dataset[\"train\"][example_index].get('context','')\n",
    "        example_question = dataset[\"train\"][example_index].get('question','')\n",
    "        if 'answers' in dataset[\"train\"][example_index] and 'text' in dataset[\"train\"][example_index]['answers'] and len(dataset[\"train\"][example_index]['answers']['text'])>0:\n",
    "            example_answer = dataset[\"train\"][example_index]['answers']['text'][0]\n",
    "        else:\n",
    "             example_answer = ''\n",
    "        qa_few_shot_prompt += f\"\\n\\nContext:\\n{example_context}\\n\\nQuestion:\\n{example_question}\\n\\nAnswer:\\n{example_answer}\\n\\n-----\"\n",
    "\n",
    "    qa_few_shot_prompt += f\"\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\"\n",
    "\n",
    "    return qa_few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the given Question based on the provided Context. Don't use any other information\n",
      "\n",
      "Context:\n",
      "The governing bodies in each country operate league systems in a domestic season, normally comprising several divisions, in which the teams gain points throughout the season depending on results. Teams are placed into tables, placing them in order according to points accrued. Most commonly, each team plays every other team in its league at home and away in each season, in a round-robin tournament. At the end of a season, the top team is declared the champion. The top few teams may be promoted to a higher division, and one or more of the teams finishing at the bottom are relegated to a lower division.\n",
      "\n",
      "Question:\n",
      "What could happen to the top few teams at the end of the season?\n",
      "\n",
      "Answer:\n",
      "promoted to a higher division\n",
      "\n",
      "-----\n",
      "\n",
      "Context:\n",
      "GE's history of working with turbines in the power-generation field gave them the engineering know-how to move into the new field of aircraft turbosuperchargers.[citation needed] Led by Sanford Alexander Moss, GE introduced the first superchargers during World War I, and continued to develop them during the Interwar period. Superchargers became indispensable in the years immediately prior to World War II, and GE was the world leader in exhaust-driven supercharging when the war started. This experience, in turn, made GE a natural selection to develop the Whittle W.1 jet engine that was demonstrated in the United States in 1941. GE ranked ninth among United States corporations in the value of wartime production contracts. Although their early work with Whittle's designs was later handed to Allison Engine Company, GE Aviation emerged as one of the world's largest engine manufacturers, second only to the British company, Rolls-Royce plc.\n",
      "\n",
      "Question:\n",
      "What engines did Rolls-Royce plc. build?\n",
      "\n",
      "Answer:\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "Context:\n",
      "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "\n",
      "Question:\n",
      "In what country is Normandy located?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_few_shot_prompt(context=dataset[\"validation\"][0][\"context\"], question=dataset[\"validation\"][0][\"question\"], num_shots=2, prompt_index=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human/Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def create_qa_model_result(num_test_examples: int, output_csv_file: str, random_sample: bool = False) -> pd.DataFrame:\n",
    "    if random_sample:\n",
    "        test_examples_indices = random.sample(range(TEST_DATA_COUNT), num_test_examples)\n",
    "    else:\n",
    "        test_examples_indices = range(num_test_examples)\n",
    "\n",
    "    test_indices, test_contexts, test_questions, test_answers = [],[],[],[]\n",
    "    zero_shot_prediction_answers_1, zero_shot_prediction_answers_2, zero_shot_prediction_answers_3 = [],[],[]\n",
    "    one_shot_prediction_answers_1, one_shot_prediction_answers_2, one_shot_prediction_answers_3 = [],[],[]\n",
    "    few_shot_prediction_answers_1, few_shot_prediction_answers_2, few_shot_prediction_answers_3 = [],[],[]\n",
    "\n",
    "    for test_index in tqdm(test_examples_indices):\n",
    "        test_context = dataset[\"validation\"][test_index].get('context','')\n",
    "        test_question = dataset[\"validation\"][test_index].get('question','')\n",
    "        if 'answers' in dataset[\"validation\"][test_index] and 'text' in dataset[\"validation\"][test_index]['answers'] and len(dataset[\"validation\"][test_index]['answers']['text'])>0:\n",
    "            test_answer = dataset[\"validation\"][test_index]['answers']['text'][0]\n",
    "        else:\n",
    "            test_answer = ''\n",
    "             \n",
    "        test_indices.append(test_index)\n",
    "        test_contexts.append(test_context)\n",
    "        test_questions.append(test_question)\n",
    "        test_answers.append(test_answer)\n",
    "\n",
    "        for prompt_index in range(1,4):\n",
    "            zero_shot_prompt = create_zero_shot_prompt(context = test_context, question = test_question, prompt_index = prompt_index)\n",
    "            zero_shot_output = generate_llm_prediction(zero_shot_prompt)\n",
    "            one_shot_prompt = create_one_shot_prompt(context = test_context, question = test_question, example_index=prompt_index, prompt_index = prompt_index)\n",
    "            one_shot_output = generate_llm_prediction(one_shot_prompt)\n",
    "            few_shot_prompt = create_few_shot_prompt(context = test_context, question = test_question, num_shots=3, prompt_index = prompt_index)\n",
    "            few_shot_output = generate_llm_prediction(few_shot_prompt)\n",
    "\n",
    "            if prompt_index == 1:\n",
    "                zero_shot_prediction_answers_1.append(zero_shot_output)\n",
    "                one_shot_prediction_answers_1.append(one_shot_output)\n",
    "                few_shot_prediction_answers_1.append(few_shot_output)\n",
    "            elif prompt_index == 2:\n",
    "                zero_shot_prediction_answers_2.append(zero_shot_output)\n",
    "                one_shot_prediction_answers_2.append(one_shot_output)\n",
    "                few_shot_prediction_answers_2.append(few_shot_output)\n",
    "            else:\n",
    "                zero_shot_prediction_answers_3.append(zero_shot_output)\n",
    "                one_shot_prediction_answers_3.append(one_shot_output)\n",
    "                few_shot_prediction_answers_3.append(few_shot_output)\n",
    "\n",
    "    df = pd.DataFrame({'Index':test_indices,'Context':test_contexts,'Question':test_questions,'Gold Summary':test_answers,\n",
    "                       'Zero_Shot_Pred_1':zero_shot_prediction_answers_1,'Zero_Shot_Pred_2':zero_shot_prediction_answers_2,'Zero_Shot_Pred_3':zero_shot_prediction_answers_3,\n",
    "                       'One_Shot_Pred_1':one_shot_prediction_answers_1,'One_Shot_Pred_2':one_shot_prediction_answers_2,'One_Shot_Pred_3':one_shot_prediction_answers_3,\n",
    "                       'Few_Shot_Pred_1':few_shot_prediction_answers_1,'Few_Shot_Pred_2':few_shot_prediction_answers_2,'Few_Shot_Pred_3':few_shot_prediction_answers_3,\n",
    "                      })\n",
    "    df.to_csv(output_csv_file,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:20<00:00,  4.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Summary</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11083</td>\n",
       "      <td>One of the most famous people born in Warsaw was Maria Skłodowska-Curie, who achieved international recognition for her research on radioactivity and was the first female recipient of the Nobel Prize. Famous musicians include Władysław Szpilman and Frédéric Chopin. Though Chopin was born in the village of Żelazowa Wola, about 60 km (37 mi) from Warsaw, he moved to the city with his family when he was seven months old. Casimir Pulaski, a Polish general and hero of the American Revolutionary War, was born here in 1745.</td>\n",
       "      <td>What year was Casimir Wola born in Warsaw?</td>\n",
       "      <td></td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "      <td>1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043</td>\n",
       "      <td>On 18 November 2015, Sky announced Sky Q, a range of products and services to be available in 2016. The Sky Q range consists of three set top boxes (Sky Q, Sky Q Silver and Sky Q Mini), a broadband router (Sky Q Hub) and mobile applications. The Sky Q set top boxes introduce a new user interface, Wi-Fi hotspot functionality, Power-line and Bluetooth connectivity and a new touch-sensitive remote control. The Sky Q Mini set top boxes connect to the Sky Q Silver set top boxes with a Wi-Fi or Power-line connection rather than receive their own satellite feeds. This allows all set top boxes in a household to share recordings and other media. The Sky Q Silver set top box is capable of receiving and displaying UHD broadcasts, which Sky will introduce later in 2016.</td>\n",
       "      <td>What is the name of Sky Q's dial-up router?</td>\n",
       "      <td></td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "      <td>Sky Q Hub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5885</td>\n",
       "      <td>The modern trend in design is toward integration of previously separated specialties, especially among large firms. In the past, architects, interior designers, engineers, developers, construction managers, and general contractors were more likely to be entirely separate companies, even in the larger firms. Presently, a firm that is nominally an \"architecture\" or \"construction management\" firm may have experts from all related fields as employees, or to have an associated company that provides each necessary skill. Thus, each such firm may offer itself as \"one-stop shopping\" for a construction project, from beginning to end. This is designated as a \"design build\" contract where the contractor is given a performance specification and must undertake the project from design to construction, while adhering to the performance specifications.</td>\n",
       "      <td>The modern trend in design is toward integration of what?</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "      <td>previously separated specialties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4495</td>\n",
       "      <td>Merit Network, Inc., an independent non-profit 501(c)(3) corporation governed by Michigan's public universities, was formed in 1966 as the Michigan Educational Research Information Triad to explore computer networking between three of Michigan's public universities as a means to help the state's educational and economic development. With initial support from the State of Michigan and the National Science Foundation (NSF), the packet-switched network was first demonstrated in December 1971 when an interactive host to host connection was made between the IBM mainframe computer systems at the University of Michigan in Ann Arbor and Wayne State University in Detroit. In October 1972 connections to the CDC mainframe at Michigan State University in East Lansing completed the triad. Over the next several years in addition to host to host interactive connections the network was enhanced to support terminal to host connections, host to host batch connections (remote job submission, remote printing, batch file transfer), interactive file transfer, gateways to the Tymnet and Telenet public data networks, X.25 host attachments, gateways to X.25 data networks, Ethernet attached hosts, and eventually TCP/IP and additional public universities in Michigan join the network. All of this set the stage for Merit's role in the NSFNET project starting in the mid-1980s.</td>\n",
       "      <td>What was eventual Merits role?</td>\n",
       "      <td></td>\n",
       "      <td>TCP/IP and additional public universities in Michigan join the network</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan join the network</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan join the network</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan</td>\n",
       "      <td>TCP/IP and additional public universities in Michigan</td>\n",
       "      <td>TCP/IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7184</td>\n",
       "      <td>Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock. By contrast, the vast majority of the population is dependent on income in the form of a wage or salary. In order to rectify this situation, socialists argue that the means of production should be socially owned so that income differentials would be reflective of individual contributions to the social product.</td>\n",
       "      <td>How do socialists think the means of production shouldn't be owned?</td>\n",
       "      <td></td>\n",
       "      <td>so that income differentials would be reflective of individual contributions to the social product</td>\n",
       "      <td>so that income differentials would be reflective of individual contributions to the social product.</td>\n",
       "      <td>Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>so that income differentials would be reflective of individual contributions to the social product</td>\n",
       "      <td>Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock.</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>so that income differentials would be reflective of individual contributions to the social product</td>\n",
       "      <td>Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  \\\n",
       "0  11083   \n",
       "1   1043   \n",
       "2   5885   \n",
       "3   4495   \n",
       "4   7184   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Context  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 One of the most famous people born in Warsaw was Maria Skłodowska-Curie, who achieved international recognition for her research on radioactivity and was the first female recipient of the Nobel Prize. Famous musicians include Władysław Szpilman and Frédéric Chopin. Though Chopin was born in the village of Żelazowa Wola, about 60 km (37 mi) from Warsaw, he moved to the city with his family when he was seven months old. Casimir Pulaski, a Polish general and hero of the American Revolutionary War, was born here in 1745.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           On 18 November 2015, Sky announced Sky Q, a range of products and services to be available in 2016. The Sky Q range consists of three set top boxes (Sky Q, Sky Q Silver and Sky Q Mini), a broadband router (Sky Q Hub) and mobile applications. The Sky Q set top boxes introduce a new user interface, Wi-Fi hotspot functionality, Power-line and Bluetooth connectivity and a new touch-sensitive remote control. The Sky Q Mini set top boxes connect to the Sky Q Silver set top boxes with a Wi-Fi or Power-line connection rather than receive their own satellite feeds. This allows all set top boxes in a household to share recordings and other media. The Sky Q Silver set top box is capable of receiving and displaying UHD broadcasts, which Sky will introduce later in 2016.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The modern trend in design is toward integration of previously separated specialties, especially among large firms. In the past, architects, interior designers, engineers, developers, construction managers, and general contractors were more likely to be entirely separate companies, even in the larger firms. Presently, a firm that is nominally an \"architecture\" or \"construction management\" firm may have experts from all related fields as employees, or to have an associated company that provides each necessary skill. Thus, each such firm may offer itself as \"one-stop shopping\" for a construction project, from beginning to end. This is designated as a \"design build\" contract where the contractor is given a performance specification and must undertake the project from design to construction, while adhering to the performance specifications.   \n",
       "3  Merit Network, Inc., an independent non-profit 501(c)(3) corporation governed by Michigan's public universities, was formed in 1966 as the Michigan Educational Research Information Triad to explore computer networking between three of Michigan's public universities as a means to help the state's educational and economic development. With initial support from the State of Michigan and the National Science Foundation (NSF), the packet-switched network was first demonstrated in December 1971 when an interactive host to host connection was made between the IBM mainframe computer systems at the University of Michigan in Ann Arbor and Wayne State University in Detroit. In October 1972 connections to the CDC mainframe at Michigan State University in East Lansing completed the triad. Over the next several years in addition to host to host interactive connections the network was enhanced to support terminal to host connections, host to host batch connections (remote job submission, remote printing, batch file transfer), interactive file transfer, gateways to the Tymnet and Telenet public data networks, X.25 host attachments, gateways to X.25 data networks, Ethernet attached hosts, and eventually TCP/IP and additional public universities in Michigan join the network. All of this set the stage for Merit's role in the NSFNET project starting in the mid-1980s.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock. By contrast, the vast majority of the population is dependent on income in the form of a wage or salary. In order to rectify this situation, socialists argue that the means of production should be socially owned so that income differentials would be reflective of individual contributions to the social product.   \n",
       "\n",
       "                                                              Question  \\\n",
       "0                           What year was Casimir Wola born in Warsaw?   \n",
       "1                          What is the name of Sky Q's dial-up router?   \n",
       "2            The modern trend in design is toward integration of what?   \n",
       "3                                      What was eventual Merits role?    \n",
       "4  How do socialists think the means of production shouldn't be owned?   \n",
       "\n",
       "                       Gold Summary  \\\n",
       "0                                     \n",
       "1                                     \n",
       "2  previously separated specialties   \n",
       "3                                     \n",
       "4                                     \n",
       "\n",
       "                                                                                     Zero_Shot_Pred_1  \\\n",
       "0                                                                                                1745   \n",
       "1                                                                                           Sky Q Hub   \n",
       "2                                                                    previously separated specialties   \n",
       "3                              TCP/IP and additional public universities in Michigan join the network   \n",
       "4  so that income differentials would be reflective of individual contributions to the social product   \n",
       "\n",
       "                                                                                      Zero_Shot_Pred_2  \\\n",
       "0                                                                                                 1745   \n",
       "1                                                                                            Sky Q Hub   \n",
       "2                                                                     previously separated specialties   \n",
       "3                               TCP/IP and additional public universities in Michigan join the network   \n",
       "4  so that income differentials would be reflective of individual contributions to the social product.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Zero_Shot_Pred_3  \\\n",
       "0                                                                                                                                                                                                                                                                                                                    1745   \n",
       "1                                                                                                                                                                                                                                                                                                               Sky Q Hub   \n",
       "2                                                                                                                                                                                                                                                                                        previously separated specialties   \n",
       "3                                                                                                                                                                                                                                                                   TCP/IP and additional public universities in Michigan   \n",
       "4  Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock   \n",
       "\n",
       "                                                           One_Shot_Pred_1  \\\n",
       "0                                                                    1745    \n",
       "1                                                               Sky Q Hub    \n",
       "2                                        previously separated specialties    \n",
       "3  TCP/IP and additional public universities in Michigan join the network    \n",
       "4                                                            unanswerable    \n",
       "\n",
       "                                                                                       One_Shot_Pred_2  \\\n",
       "0                                                                                                1745    \n",
       "1                                                                                           Sky Q Hub    \n",
       "2                                                                    previously separated specialties    \n",
       "3                                               TCP/IP and additional public universities in Michigan    \n",
       "4  so that income differentials would be reflective of individual contributions to the social product    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                            One_Shot_Pred_3  \\\n",
       "0                                                                                                                                                                                                                                                                                                                     1745    \n",
       "1                                                                                                                                                                                                                                                                                                                Sky Q Hub    \n",
       "2                                                                                                                                                                                                                                                                                         previously separated specialties    \n",
       "3                                                                                                                                                                                                                                                                    TCP/IP and additional public universities in Michigan    \n",
       "4  Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners, creating a situation where a small portion of the population lives off unearned property income by virtue of ownership titles in capital equipment, financial assets and corporate stock.    \n",
       "\n",
       "                                          Few_Shot_Pred_1  \\\n",
       "0                                                   1745    \n",
       "1                                              Sky Q Hub    \n",
       "2                       previously separated specialties    \n",
       "3  TCP/IP and additional public universities in Michigan    \n",
       "4                                           unanswerable    \n",
       "\n",
       "                                                                                       Few_Shot_Pred_2  \\\n",
       "0                                                                                                1745    \n",
       "1                                                                                           Sky Q Hub    \n",
       "2                                                                    previously separated specialties    \n",
       "3                                               TCP/IP and additional public universities in Michigan    \n",
       "4  so that income differentials would be reflective of individual contributions to the social product    \n",
       "\n",
       "                                                                                                                 Few_Shot_Pred_3  \n",
       "0                                                                                                                          1745   \n",
       "1                                                                                                                     Sky Q Hub   \n",
       "2                                                                                              previously separated specialties   \n",
       "3                                                                                                                        TCP/IP   \n",
       "4  Socialists attribute the vast disparities in wealth to the private ownership of the means of production by a class of owners   "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_qa_model_result(num_test_examples = 5, output_csv_file = 'QA_Evaluation_Sample_5.csv', random_sample = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Analysis:\n",
    "\n",
    "1. Current Model QA results are comparatively better as compared to summarization task. The model generally gives the correct result although the results is not specific as present in the gold answers\n",
    "2. We also analyze the quantitative results in the next section to get a better understanding of the entire test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric/Quantitative Evaluation\n",
    "\n",
    "We will use **[ROUGE](https://https://huggingface.co/spaces/evaluate-metric/rouge)** metric for our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                             | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:48<00:00,  3.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Summary</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>What century did the Normans first gain their separate identity?</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th century</td>\n",
       "      <td>10th</td>\n",
       "      <td>10th</td>\n",
       "      <td>10th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
       "1  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
       "2  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
       "3  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
       "4  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
       "\n",
       "                                                           Question  \\\n",
       "0                              In what country is Normandy located?   \n",
       "1                                When were the Normans in Normandy?   \n",
       "2                     From which countries did the Norse originate?   \n",
       "3                                         Who was the Norse leader?   \n",
       "4  What century did the Normans first gain their separate identity?   \n",
       "\n",
       "                  Gold Summary             Zero_Shot_Pred_1  \\\n",
       "0                       France                       France   \n",
       "1      10th and 11th centuries      10th and 11th centuries   \n",
       "2  Denmark, Iceland and Norway  Denmark, Iceland and Norway   \n",
       "3                        Rollo                        Rollo   \n",
       "4                 10th century                 10th century   \n",
       "\n",
       "              Zero_Shot_Pred_2             Zero_Shot_Pred_3  \\\n",
       "0                       France                       France   \n",
       "1      10th and 11th centuries      10th and 11th centuries   \n",
       "2  Denmark, Iceland and Norway  Denmark, Iceland and Norway   \n",
       "3                        Rollo                        Rollo   \n",
       "4                 10th century                 10th century   \n",
       "\n",
       "                One_Shot_Pred_1               One_Shot_Pred_2  \\\n",
       "0                       France                        France    \n",
       "1      10th and 11th centuries       10th and 11th centuries    \n",
       "2  Denmark, Iceland and Norway   Denmark, Iceland and Norway    \n",
       "3                        Rollo                         Rollo    \n",
       "4                 10th century                  10th century    \n",
       "\n",
       "                One_Shot_Pred_3               Few_Shot_Pred_1  \\\n",
       "0                       France                        France    \n",
       "1      10th and 11th centuries       10th and 11th centuries    \n",
       "2  Denmark, Iceland and Norway   Denmark, Iceland and Norway    \n",
       "3                        Rollo                         Rollo    \n",
       "4                 10th century                          10th    \n",
       "\n",
       "                Few_Shot_Pred_2               Few_Shot_Pred_3  \n",
       "0                       France                        France   \n",
       "1      10th and 11th centuries       10th and 11th centuries   \n",
       "2  Denmark, Iceland and Norway   Denmark, Iceland and Norway   \n",
       "3                        Rollo                         Rollo   \n",
       "4                         10th                          10th   "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "df = create_qa_model_result(num_test_examples = 100, output_csv_file = 'QA_Evaluation_100_samples.csv', random_sample = False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_1</th>\n",
       "      <td>0.372901</td>\n",
       "      <td>0.166798</td>\n",
       "      <td>0.373461</td>\n",
       "      <td>0.371901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_2</th>\n",
       "      <td>0.378381</td>\n",
       "      <td>0.164298</td>\n",
       "      <td>0.377333</td>\n",
       "      <td>0.376214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_3</th>\n",
       "      <td>0.32178</td>\n",
       "      <td>0.14269</td>\n",
       "      <td>0.319766</td>\n",
       "      <td>0.322031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_1</th>\n",
       "      <td>0.359464</td>\n",
       "      <td>0.15469</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.359774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_2</th>\n",
       "      <td>0.362279</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.36136</td>\n",
       "      <td>0.363381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_3</th>\n",
       "      <td>0.356888</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.355547</td>\n",
       "      <td>0.357417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_1</th>\n",
       "      <td>0.358107</td>\n",
       "      <td>0.134821</td>\n",
       "      <td>0.355845</td>\n",
       "      <td>0.357607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_2</th>\n",
       "      <td>0.358917</td>\n",
       "      <td>0.143857</td>\n",
       "      <td>0.357607</td>\n",
       "      <td>0.358917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_3</th>\n",
       "      <td>0.332827</td>\n",
       "      <td>0.13144</td>\n",
       "      <td>0.329642</td>\n",
       "      <td>0.330827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rouge1    rouge2    rougeL rougeLSum\n",
       "Zero_Shot_Prompt_1  0.372901  0.166798  0.373461  0.371901\n",
       "Zero_Shot_Prompt_2  0.378381  0.164298  0.377333  0.376214\n",
       "Zero_Shot_Prompt_3   0.32178   0.14269  0.319766  0.322031\n",
       "One_Shot_Prompt_1   0.359464   0.15469     0.359  0.359774\n",
       "One_Shot_Prompt_2   0.362279  0.156524   0.36136  0.363381\n",
       "One_Shot_Prompt_3   0.356888  0.156524  0.355547  0.357417\n",
       "Few_Shot_Prompt_1   0.358107  0.134821  0.355845  0.357607\n",
       "Few_Shot_Prompt_2   0.358917  0.143857  0.357607  0.358917\n",
       "Few_Shot_Prompt_3   0.332827   0.13144  0.329642  0.330827"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = create_rouge_eval_result(df, output_csv_file = 'QA_Evaluation_100_samples_Metrics.csv', gold_column = 'Gold Summary') \n",
    "df_res.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 Summary\n",
    "1. The results are comparatively similar with an average Rouge of 0.37\n",
    "2. The results can further be improvised by\n",
    "   - Experimenting with other prompts\n",
    "   - Experimenting with different configuration parameters of the model (e.g: do_sample=True for different decoding strategies)\n",
    "   - Perform fine-tuning on data\n",
    "   - Using a larger parameters model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Verify if English to French translation task works.\n",
    "\n",
    "We will experiment with samples from **[DiaBLa](https://huggingface.co/datasets/rbawden/DiaBLa)** dataset for Translation task.\n",
    "\n",
    "The dataset is an English-French dataset for the evaluation of Machine Translation (MT) for informal, written bilingual dialogue.\n",
    "\n",
    "The dataset contains 144 spontaneous dialogues (5,700+ sentences) between native English and French speakers, mediated by one of two neural MT systems in a range of role-play settings. See below for some basic statistics. The dialogues are accompanied by fine-grained sentence-level judgments of MT quality, produced by the dialogue participants themselves, as well as by manually normalised versions and reference translations produced a posteriori. See here for information about evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 5748\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset_name = \"rbawden/DiaBLa\"\n",
    "dataset = datasets.load_dataset(dataset_name)\n",
    "\n",
    "TEST_DATA_COUNT = len(dataset['test'])\n",
    "print(f\"Test dataset size: {TEST_DATA_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_COUNT = 5000\n",
    "TEST_DATA_COUNT = 748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue_history': [],\n",
      " 'dialogue_meta': {'end_time': '',\n",
      "                   'final_evaluation_user1': {'coherence': 'average',\n",
      "                                              'grammaticality': 'good',\n",
      "                                              'meaning': 'average',\n",
      "                                              'style': 'average',\n",
      "                                              'word_choice': 'average'},\n",
      "                   'final_evaluation_user2': {'coherence': '',\n",
      "                                              'grammaticality': '',\n",
      "                                              'meaning': '',\n",
      "                                              'style': '',\n",
      "                                              'word_choice': ''},\n",
      "                   'scenario': [['You are both stuck in a lift at work.',\n",
      "                                 'Vous êtes tous les deux bloqué(e)s dans un '\n",
      "                                 'ascenseur au travail.'],\n",
      "                                ['You are an employee and you are with your '\n",
      "                                 'boss.',\n",
      "                                 'Vous êtes un(e) employé(e) et vous êtes avez '\n",
      "                                 'votre patron(ne)'],\n",
      "                                ['You are the boss and are with an employee.',\n",
      "                                 'Vous êtes le ou la patron(ne) et vous êtes '\n",
      "                                 'avec un(e) employé(e)']],\n",
      "                   'start_time': '2018-04-25T16:20:36.087170',\n",
      "                   'translation_model': 'baseline',\n",
      "                   'user1': {'initiated_dialogue': True,\n",
      "                             'lang': 'french',\n",
      "                             'role': ['You are an employee and you are with '\n",
      "                                      'your boss.',\n",
      "                                      'Vous êtes un(e) employé(e) et vous êtes '\n",
      "                                      'avez votre patron(ne)'],\n",
      "                             'role_num': 1,\n",
      "                             'turn_number': 2},\n",
      "                   'user2': {'initiated_dialogue': False,\n",
      "                             'lang': 'english',\n",
      "                             'role': ['You are the boss and are with an '\n",
      "                                      'employee.',\n",
      "                                      'Vous êtes le ou la patron(ne) et vous '\n",
      "                                      'êtes avec un(e) employé(e)'],\n",
      "                             'role_num': 2,\n",
      "                             'turn_number': 1}},\n",
      " 'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_0',\n",
      " 'mt': 'On semble avoir arrêté de bouger.',\n",
      " 'norm': '',\n",
      " 'orig': 'We appear to have stopped moving.',\n",
      " 'ref': \"J'ai l'impression qu'on s'est arrêtés.\",\n",
      " 'utterance_meta': {'eval_judgment': 'medium',\n",
      "                    'eval_problems': ['style'],\n",
      "                    'eval_verbatim': '',\n",
      "                    'lang': 'english'}}\n"
     ]
    }
   ],
   "source": [
    "# Sample Data\n",
    "from pprint import pprint \n",
    "sample_data = next(iter(dataset['test']))\n",
    "pprint(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue_history': [{'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_0',\n",
      "                       'mt': 'On semble avoir arrêté de bouger.',\n",
      "                       'norm': '',\n",
      "                       'orig': 'We appear to have stopped moving.',\n",
      "                       'ref': \"J'ai l'impression qu'on s'est arrêtés.\",\n",
      "                       'utterance_meta': {'eval_judgment': 'medium',\n",
      "                                          'eval_problems': ['style'],\n",
      "                                          'eval_verbatim': '',\n",
      "                                          'lang': 'english'}},\n",
      "                      {'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_1',\n",
      "                       'mt': 'Je ne te paye pas pour rester là.',\n",
      "                       'norm': '',\n",
      "                       'orig': \"I don't pay you to just stand there.\",\n",
      "                       'ref': 'Je ne vous paye pas à rester là debout à rien '\n",
      "                              'faire.',\n",
      "                       'utterance_meta': {'eval_judgment': 'medium',\n",
      "                                          'eval_problems': ['meaning'],\n",
      "                                          'eval_verbatim': '',\n",
      "                                          'lang': 'english'}},\n",
      "                      {'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_2',\n",
      "                       'mt': 'Fais quelque chose.',\n",
      "                       'norm': '',\n",
      "                       'orig': 'DO something.',\n",
      "                       'ref': 'FAITES quelque chose.',\n",
      "                       'utterance_meta': {'eval_judgment': 'perfect',\n",
      "                                          'eval_problems': [],\n",
      "                                          'eval_verbatim': '',\n",
      "                                          'lang': 'english'}},\n",
      "                      {'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_3',\n",
      "                       'mt': \"You're absolutely right, I'll try to call the \"\n",
      "                             'front desk.',\n",
      "                       'norm': '',\n",
      "                       'orig': 'Vous avez tout à fait raison, je vais essayer '\n",
      "                               \"de téléphoner à l'accueil.\",\n",
      "                       'ref': \"You're totally right. I'll try to call \"\n",
      "                              'reception.',\n",
      "                       'utterance_meta': {'eval_judgment': 'perfect',\n",
      "                                          'eval_problems': [],\n",
      "                                          'eval_verbatim': 'looks good',\n",
      "                                          'lang': 'french'}}],\n",
      " 'dialogue_meta': {'end_time': '',\n",
      "                   'final_evaluation_user1': {'coherence': 'average',\n",
      "                                              'grammaticality': 'good',\n",
      "                                              'meaning': 'average',\n",
      "                                              'style': 'average',\n",
      "                                              'word_choice': 'average'},\n",
      "                   'final_evaluation_user2': {'coherence': '',\n",
      "                                              'grammaticality': '',\n",
      "                                              'meaning': '',\n",
      "                                              'style': '',\n",
      "                                              'word_choice': ''},\n",
      "                   'scenario': [['You are both stuck in a lift at work.',\n",
      "                                 'Vous êtes tous les deux bloqué(e)s dans un '\n",
      "                                 'ascenseur au travail.'],\n",
      "                                ['You are an employee and you are with your '\n",
      "                                 'boss.',\n",
      "                                 'Vous êtes un(e) employé(e) et vous êtes avez '\n",
      "                                 'votre patron(ne)'],\n",
      "                                ['You are the boss and are with an employee.',\n",
      "                                 'Vous êtes le ou la patron(ne) et vous êtes '\n",
      "                                 'avec un(e) employé(e)']],\n",
      "                   'start_time': '2018-04-25T16:20:36.087170',\n",
      "                   'translation_model': 'baseline',\n",
      "                   'user1': {'initiated_dialogue': True,\n",
      "                             'lang': 'french',\n",
      "                             'role': ['You are an employee and you are with '\n",
      "                                      'your boss.',\n",
      "                                      'Vous êtes un(e) employé(e) et vous êtes '\n",
      "                                      'avez votre patron(ne)'],\n",
      "                             'role_num': 1,\n",
      "                             'turn_number': 2},\n",
      "                   'user2': {'initiated_dialogue': False,\n",
      "                             'lang': 'english',\n",
      "                             'role': ['You are the boss and are with an '\n",
      "                                      'employee.',\n",
      "                                      'Vous êtes le ou la patron(ne) et vous '\n",
      "                                      'êtes avec un(e) employé(e)'],\n",
      "                             'role_num': 2,\n",
      "                             'turn_number': 1}},\n",
      " 'id': 'dialogue-2018-04-25T16-20-36.087170_french_english_1_2_4',\n",
      " 'mt': 'They should be able to help us out.',\n",
      " 'norm': '',\n",
      " 'orig': 'Ils devraient pouvoir nous dépanner.',\n",
      " 'ref': 'They should be able to help us out.',\n",
      " 'utterance_meta': {'eval_judgment': 'perfect',\n",
      "                    'eval_problems': [],\n",
      "                    'eval_verbatim': 'good',\n",
      "                    'lang': 'french'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset['test'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset: datasets.Dataset) -> dict:\n",
    "\n",
    "    source_texts = []\n",
    "    target_texts = []\n",
    "\n",
    "    for sample_data in dataset['test']:\n",
    "        lang = sample_data['utterance_meta']['lang']\n",
    "        if lang == 'french':\n",
    "            source_texts.append(sample_data.get('ref',''))\n",
    "            target_texts.append(sample_data.get('orig',''))\n",
    "        else:\n",
    "            source_texts.append(sample_data.get('orig',''))\n",
    "            target_texts.append(sample_data.get('ref',''))\n",
    "        \n",
    "    train_source_texts = source_texts[:5000]\n",
    "    train_target_texts = target_texts[:5000]\n",
    "    test_source_texts = source_texts[5000:]\n",
    "    test_target_texts = target_texts[5000:]\n",
    "    \n",
    "    return {'sources':train_source_texts, 'targets':train_target_texts}, {'sources':test_source_texts, 'targets':test_target_texts}\n",
    "\n",
    "train_data, test_data = read_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt(source: str, prompt_index: int) -> str:\n",
    "    if prompt_index == 1:\n",
    "        translation_zero_shot_prompt = f\"\"\"Translate the following dialogue from English to French\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        translation_zero_shot_prompt = f\"\"\"Please provide a French translation of the following English dialogue\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        translation_zero_shot_prompt = f\"\"\"Translate the following dialogue from English to French. Return only the translated French sentence\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "    return translation_zero_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following dialogue from English to French\n",
      "\n",
      "English:\n",
      "how long have you been feeling like this?\n",
      "\n",
      "French:\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_zero_shot_prompt(source=test_data['sources'][0], prompt_index=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_shot_prompt(source: str,  example_index: int, prompt_index: int) -> str:\n",
    "\n",
    "    example_source = train_data['sources'][example_index]\n",
    "    example_target = train_data['targets'][example_index]\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        translation_one_shot_prompt = f\"\"\"Translate the following dialogue from English to French\\n\\nEnglish:\\n{example_source}\\n\\nFrench:\\n{example_target}\\n\\n-----\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        translation_one_shot_prompt = f\"\"\"Please provide a French translation of the following English dialogue\\n\\nEnglish:\\n{example_source}\\n\\nFrench:\\n{example_target}\\n\\n-----\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        translation_one_shot_prompt = f\"\"\"Translate the following dialogue from English to French. Return only the translated French sentence\\n\\nEnglish:\\n{example_source}\\n\\nFrench:\\n{example_target}\\n\\n-----\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\n",
    "        \"\"\"\n",
    "    return translation_one_shot_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following dialogue from English to French\n",
      "\n",
      "English:\n",
      "You're totally right. I'll try to call reception.\n",
      "\n",
      "French:\n",
      "Vous avez tout à fait raison, je vais essayer de téléphoner à l'accueil.\n",
      "\n",
      "-----\n",
      "\n",
      "English:\n",
      "how long have you been feeling like this?\n",
      "\n",
      "French:\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(create_one_shot_prompt(source=test_data['sources'][0],  example_index=3, prompt_index=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(source: str, num_shots: int, prompt_index: int) -> str:\n",
    "\n",
    "    indices = random.sample(range(TRAINING_DATA_COUNT), num_shots)\n",
    "\n",
    "    if prompt_index == 1:\n",
    "        translation_few_shot_prompt = f\"\"\"Translate the following dialogue from English to French\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 2:\n",
    "        translation_few_shot_prompt = f\"\"\"Please provide a French translation of the following English dialogue\n",
    "        \"\"\"\n",
    "\n",
    "    elif prompt_index == 3:\n",
    "        translation_few_shot_prompt = f\"\"\"Translate the following dialogue from English to French. Return only the translated French sentence\n",
    "        \"\"\"\n",
    "\n",
    "    for example_index in indices:\n",
    "        example_source = train_data['sources'][example_index]\n",
    "        example_target = train_data['targets'][example_index]\n",
    "        translation_few_shot_prompt += f\"\\n\\nEnglish:\\n{example_source}\\n\\nFrench:\\n{example_target}\\n\\n-----\"\n",
    "\n",
    "    translation_few_shot_prompt += f\"\\n\\nEnglish:\\n{source}\\n\\nFrench:\\n\"\n",
    "    \n",
    "    return translation_few_shot_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following dialogue from English to French\n",
      "        \n",
      "\n",
      "English:\n",
      "So have you made a guest list for the party?\n",
      "\n",
      "French:\n",
      "Alors, est-ce que tu as préparé une liste d'invités pour la soirée ?\n",
      "\n",
      "-----\n",
      "\n",
      "English:\n",
      "I think I need a plaster.\n",
      "\n",
      "French:\n",
      "J'ai besoin d'un pansement.\n",
      "\n",
      "-----\n",
      "\n",
      "English:\n",
      "how long have you been feeling like this?\n",
      "\n",
      "French:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_few_shot_prompt(source=test_data['sources'][0], num_shots=2, prompt_index=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human/Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def create_translation_model_result(num_test_examples: int, output_csv_file: str, random_sample: bool = False) -> pd.DataFrame:\n",
    "    if random_sample:\n",
    "        test_examples_indices = random.sample(range(TEST_DATA_COUNT), num_test_examples)\n",
    "    else:\n",
    "        test_examples_indices = range(num_test_examples)\n",
    "\n",
    "    test_indices, test_sources, test_targets = [],[],[]\n",
    "    zero_shot_prediction_targets_1, zero_shot_prediction_targets_2, zero_shot_prediction_targets_3 = [],[],[]\n",
    "    one_shot_prediction_targets_1, one_shot_prediction_targets_2, one_shot_prediction_targets_3 = [],[],[]\n",
    "    few_shot_prediction_targets_1, few_shot_prediction_targets_2, few_shot_prediction_targets_3 = [],[],[]\n",
    "\n",
    "    for test_index in tqdm(test_examples_indices):\n",
    "        test_source = test_data['sources'][test_index]\n",
    "        test_target = test_data['targets'][test_index]\n",
    "        test_indices.append(test_index)\n",
    "        test_sources.append(test_source)\n",
    "        test_targets.append(test_target)\n",
    "\n",
    "        for prompt_index in range(1,4):\n",
    "            zero_shot_prompt = create_zero_shot_prompt(source = test_source, prompt_index = prompt_index)\n",
    "            zero_shot_output = generate_llm_prediction(zero_shot_prompt)\n",
    "            one_shot_prompt = create_one_shot_prompt(source = test_source, example_index=prompt_index, prompt_index = prompt_index)\n",
    "            one_shot_output = generate_llm_prediction(one_shot_prompt)\n",
    "            few_shot_prompt = create_few_shot_prompt(source = test_source, num_shots=3, prompt_index = prompt_index)\n",
    "            few_shot_output = generate_llm_prediction(few_shot_prompt)\n",
    "\n",
    "            if prompt_index == 1:\n",
    "                zero_shot_prediction_targets_1.append(zero_shot_output)\n",
    "                one_shot_prediction_targets_1.append(one_shot_output)\n",
    "                few_shot_prediction_targets_1.append(few_shot_output)\n",
    "            elif prompt_index == 2:\n",
    "                zero_shot_prediction_targets_2.append(zero_shot_output)\n",
    "                one_shot_prediction_targets_2.append(one_shot_output)\n",
    "                few_shot_prediction_targets_2.append(few_shot_output)\n",
    "            else:\n",
    "                zero_shot_prediction_targets_3.append(zero_shot_output)\n",
    "                one_shot_prediction_targets_3.append(one_shot_output)\n",
    "                few_shot_prediction_targets_3.append(few_shot_output)\n",
    "\n",
    "    df = pd.DataFrame({'Index':test_indices,'Source':test_sources,'Gold Targets':test_targets,\n",
    "                       'Zero_Shot_Pred_1':zero_shot_prediction_targets_1,'Zero_Shot_Pred_2':zero_shot_prediction_targets_2,'Zero_Shot_Pred_3':zero_shot_prediction_targets_3,\n",
    "                       'One_Shot_Pred_1':one_shot_prediction_targets_1,'One_Shot_Pred_2':one_shot_prediction_targets_2,'One_Shot_Pred_3':one_shot_prediction_targets_3,\n",
    "                       'Few_Shot_Pred_1':few_shot_prediction_targets_1,'Few_Shot_Pred_2':few_shot_prediction_targets_2,'Few_Shot_Pred_3':few_shot_prediction_targets_3,\n",
    "                      })\n",
    "    df.to_csv(output_csv_file,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Source</th>\n",
       "      <th>Gold Targets</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>345</td>\n",
       "      <td>Oh no, it's just us!</td>\n",
       "      <td>Oh non, on est entre nous!</td>\n",
       "      <td>Oh no, il s'est just us!</td>\n",
       "      <td>Oh no, it's just us!</td>\n",
       "      <td>Oh no, il s'est just us!</td>\n",
       "      <td>Oh no, il y a pas à rester là de rien faire.</td>\n",
       "      <td>Oh no, it's just us!</td>\n",
       "      <td>Oh, il n'est pas seulement nous!</td>\n",
       "      <td>Oh, il y a pas d'être à l'égard de vous!</td>\n",
       "      <td>Oh no, it's just us!</td>\n",
       "      <td>Oh, il n'est pas seulement nous!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>Nothing else?</td>\n",
       "      <td>Rien d'autre ?</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Je ne vous avez pas à rester là de rien faire.</td>\n",
       "      <td></td>\n",
       "      <td>Vous avez tout à fait raison, je vais essayer de téléphoner à l'accueil.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430</td>\n",
       "      <td>I was doing as you asked, chef, but since I was busy making the starter for table 6, I didn't see the time go by and I let the cream burn...</td>\n",
       "      <td>J'ai fait comme vous m'avez demandé, chef, mais comme j'étais aussi occupée à faire l'entrée pour la table 6, j'ai pas fait attention au temps et j'ai laissé brûler la crème...</td>\n",
       "      <td>Je suis d'adopter à l'heure, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai</td>\n",
       "      <td>I was doing as you asked, chef, but since I was busy making the starter for table 6, I didn't see the time go by and I let the cream burn...</td>\n",
       "      <td>Je suis d'adopter comme vous avez demandé, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'adopter le cream...</td>\n",
       "      <td>Je a fait l'assaint, chef, mais depuis que j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai</td>\n",
       "      <td></td>\n",
       "      <td>Je a fait l'adoption à l'heure, chef, mais depuis que j'ai l'adoption à l'entrée pour le table 6, je ne peux pas voir l'heure et j'ai l'adoption à l'adoption à l'adoption à l'adoption à l'ad</td>\n",
       "      <td>Je suis d'adopter comme vous avez demandé, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'adopter le cream...</td>\n",
       "      <td>Je suis d'adopter à l'heure, chef, mais depuis longtemps j'ai l'heure pour le table 6, je ne peux pas voir l'heure et j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l</td>\n",
       "      <td>Je a fait l'assaint, chef, mais depuis que j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>Oh dear.</td>\n",
       "      <td>Ouh là.</td>\n",
       "      <td>Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d</td>\n",
       "      <td>Oh dear.</td>\n",
       "      <td>Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d</td>\n",
       "      <td>Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d</td>\n",
       "      <td>Oh dear.</td>\n",
       "      <td>Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d</td>\n",
       "      <td>Oh, dear.</td>\n",
       "      <td>Oh, dear.</td>\n",
       "      <td>Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499</td>\n",
       "      <td>A star!!</td>\n",
       "      <td>Une star !!</td>\n",
       "      <td>A star!!</td>\n",
       "      <td>A star!!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "      <td>A star!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  \\\n",
       "0    345   \n",
       "1    386   \n",
       "2    430   \n",
       "3    281   \n",
       "4    499   \n",
       "\n",
       "                                                                                                                                         Source  \\\n",
       "0                                                                                                                          Oh no, it's just us!   \n",
       "1                                                                                                                                 Nothing else?   \n",
       "2  I was doing as you asked, chef, but since I was busy making the starter for table 6, I didn't see the time go by and I let the cream burn...   \n",
       "3                                                                                                                                      Oh dear.   \n",
       "4                                                                                                                                      A star!!   \n",
       "\n",
       "                                                                                                                                                                       Gold Targets  \\\n",
       "0                                                                                                                                                        Oh non, on est entre nous!   \n",
       "1                                                                                                                                                                    Rien d'autre ?   \n",
       "2  J'ai fait comme vous m'avez demandé, chef, mais comme j'étais aussi occupée à faire l'entrée pour la table 6, j'ai pas fait attention au temps et j'ai laissé brûler la crème...   \n",
       "3                                                                                                                                                                           Ouh là.   \n",
       "4                                                                                                                                                                       Une star !!   \n",
       "\n",
       "                                                                                                                                                                     Zero_Shot_Pred_1  \\\n",
       "0                                                                                                                                                            Oh no, il s'est just us!   \n",
       "1                                                                                                                                                                                       \n",
       "2  Je suis d'adopter à l'heure, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai    \n",
       "3                                                                               Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d   \n",
       "4                                                                                                                                                                            A star!!   \n",
       "\n",
       "                                                                                                                               Zero_Shot_Pred_2  \\\n",
       "0                                                                                                                          Oh no, it's just us!   \n",
       "1                                                                                                                                                 \n",
       "2  I was doing as you asked, chef, but since I was busy making the starter for table 6, I didn't see the time go by and I let the cream burn...   \n",
       "3                                                                                                                                      Oh dear.   \n",
       "4                                                                                                                                      A star!!   \n",
       "\n",
       "                                                                                                                                                           Zero_Shot_Pred_3  \\\n",
       "0                                                                                                                                                  Oh no, il s'est just us!   \n",
       "1                                                                                                                                                                             \n",
       "2  Je suis d'adopter comme vous avez demandé, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'adopter le cream...   \n",
       "3                                                                     Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d   \n",
       "4                                                                                                                                                                   A star!   \n",
       "\n",
       "                                                                                                               One_Shot_Pred_1  \\\n",
       "0                                                                                Oh no, il y a pas à rester là de rien faire.    \n",
       "1                                                                              Je ne vous avez pas à rester là de rien faire.    \n",
       "2  Je a fait l'assaint, chef, mais depuis que j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai    \n",
       "3                        Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d   \n",
       "4                                                                                                                     A star!    \n",
       "\n",
       "                                     One_Shot_Pred_2  \\\n",
       "0                               Oh no, it's just us!   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                           Oh dear.   \n",
       "4                                            A star!   \n",
       "\n",
       "                                                                                                                                                                                  One_Shot_Pred_3  \\\n",
       "0                                                                                                                                                                Oh, il n'est pas seulement nous!   \n",
       "1                                                                                                                       Vous avez tout à fait raison, je vais essayer de téléphoner à l'accueil.    \n",
       "2  Je a fait l'adoption à l'heure, chef, mais depuis que j'ai l'adoption à l'entrée pour le table 6, je ne peux pas voir l'heure et j'ai l'adoption à l'adoption à l'adoption à l'adoption à l'ad   \n",
       "3                                                                                           Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d   \n",
       "4                                                                                                                                                                                         A star!   \n",
       "\n",
       "                                                                                                                                                            Few_Shot_Pred_1  \\\n",
       "0                                                                                                                                 Oh, il y a pas d'être à l'égard de vous!    \n",
       "1                                                                                                                                                                             \n",
       "2  Je suis d'adopter comme vous avez demandé, chef, mais depuis que je suis d'adopter le starter pour le table 6, je ne peux pas voir l'heure et j'ai l'adopter le cream...   \n",
       "3                                                                                                                                                                 Oh, dear.   \n",
       "4                                                                                                                                                                   A star!   \n",
       "\n",
       "                                                                                                                                                             Few_Shot_Pred_2  \\\n",
       "0                                                                                                                                                      Oh no, it's just us!    \n",
       "1                                                                                                                                                                              \n",
       "2  Je suis d'adopter à l'heure, chef, mais depuis longtemps j'ai l'heure pour le table 6, je ne peux pas voir l'heure et j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l   \n",
       "3                                                                                                                                                                  Oh, dear.   \n",
       "4                                                                                                                                                                   A star!    \n",
       "\n",
       "                                                                                                               Few_Shot_Pred_3  \n",
       "0                                                                                            Oh, il n'est pas seulement nous!   \n",
       "1                                                                                                                               \n",
       "2  Je a fait l'assaint, chef, mais depuis que j'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai l'ai   \n",
       "3                        Oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d'oh, d  \n",
       "4                                                                                                                     A star!   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_translation_model_result(num_test_examples = 5, output_csv_file = 'Translation_Evaluation_Sample_5.csv', random_sample = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Analysis:\n",
    "\n",
    "1. Since it is difficult to analyze the French data, we will proceed with quantitative results\n",
    "2. We analyze the quantitative results in the next section to get a better understanding of the entire test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric/Quantitative Evaluation\n",
    "\n",
    "We will use **[ROUGE](https://https://huggingface.co/spaces/evaluate-metric/rouge)** metric for our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [11:56<00:00,  7.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Source</th>\n",
       "      <th>Gold Targets</th>\n",
       "      <th>Zero_Shot_Pred_1</th>\n",
       "      <th>Zero_Shot_Pred_2</th>\n",
       "      <th>Zero_Shot_Pred_3</th>\n",
       "      <th>One_Shot_Pred_1</th>\n",
       "      <th>One_Shot_Pred_2</th>\n",
       "      <th>One_Shot_Pred_3</th>\n",
       "      <th>Few_Shot_Pred_1</th>\n",
       "      <th>Few_Shot_Pred_2</th>\n",
       "      <th>Few_Shot_Pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>516</td>\n",
       "      <td>The lift engineer or the receptionist?</td>\n",
       "      <td>L'ascensoriste ou le réceptionniste ?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td></td>\n",
       "      <td>Le ingénieur de lift ou le reservisteur?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "      <td>Le ingénieur de lift ou le réception?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>I'm guessing her child is just as beautiful as she is.</td>\n",
       "      <td>Je suis sûre que son enfant est tout aussi mignon qu'elle.</td>\n",
       "      <td>Je pense que elle s'est sa mère sa couleur sa couleur.</td>\n",
       "      <td>Je pense que elle a sa mère s'est juste mais belle que elle s'est.</td>\n",
       "      <td>Je pense que elle s'est sa mère sa couleur sa couleur.</td>\n",
       "      <td>Je pense que elle s'est tellement belle que elle s'est.</td>\n",
       "      <td>Je pense que elle a sa mère s'est juste mais belle que elle s'est.</td>\n",
       "      <td>Je pense que elle s'est tellement belle que elle s'est.</td>\n",
       "      <td>Je pense que elle s'est tellement belle que elle s'est.</td>\n",
       "      <td>Je pense que elle s'est aussi belle que elle s'est.</td>\n",
       "      <td>Je pense que elle s'est tellement belle que elle s'est.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>if that's what you can even call it</td>\n",
       "      <td>Si on peut appeler ça comme ça.</td>\n",
       "      <td>si ce serait l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de</td>\n",
       "      <td>if that's what you can even call it French</td>\n",
       "      <td>Si cela est ce qui vous pouvez ne peux pas s'est-elle-même.</td>\n",
       "      <td>Je ne vous avez pas à rester là de rien faire.</td>\n",
       "      <td>if that's what you can even call it</td>\n",
       "      <td>Vous avez tout à fait raison, je vais essayer de téléphoner à l'accueil.</td>\n",
       "      <td>Si cela est l'un vrai!</td>\n",
       "      <td>Si cela est l'unique de l'enseignement universitaire pour changer son comportement au quotidien, et pour encontrer son entourage à faire même.</td>\n",
       "      <td>Je peux aussi s'adresser à l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>686</td>\n",
       "      <td>Are there chickens there too?</td>\n",
       "      <td>Est-ce qu'il y a aussi des poulets ?</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Are there chickens too?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664</td>\n",
       "      <td>Or perhaps not.</td>\n",
       "      <td>Ou peut-être pas</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "      <td>Or, ne peut pas pas.</td>\n",
       "      <td></td>\n",
       "      <td>Or, ne peut pas pas.</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "      <td>Or, ne peut pas.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                                  Source  \\\n",
       "0    516                  The lift engineer or the receptionist?   \n",
       "1    584  I'm guessing her child is just as beautiful as she is.   \n",
       "2     23                     if that's what you can even call it   \n",
       "3    686                           Are there chickens there too?   \n",
       "4    664                                         Or perhaps not.   \n",
       "\n",
       "                                                 Gold Targets  \\\n",
       "0                       L'ascensoriste ou le réceptionniste ?   \n",
       "1  Je suis sûre que son enfant est tout aussi mignon qu'elle.   \n",
       "2                             Si on peut appeler ça comme ça.   \n",
       "3                        Est-ce qu'il y a aussi des poulets ?   \n",
       "4                                            Ou peut-être pas   \n",
       "\n",
       "                                                                                                                                                                               Zero_Shot_Pred_1  \\\n",
       "0                                                                                                                                                         Le ingénieur de lift ou le réception?   \n",
       "1                                                                                                                                        Je pense que elle s'est sa mère sa couleur sa couleur.   \n",
       "2  si ce serait l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de   \n",
       "3                                                                                                                                                                                                 \n",
       "4                                                                                                                                                                              Or, ne peut pas.   \n",
       "\n",
       "                                                     Zero_Shot_Pred_2  \\\n",
       "0                               Le ingénieur de lift ou le réception?   \n",
       "1  Je pense que elle a sa mère s'est juste mais belle que elle s'est.   \n",
       "2                          if that's what you can even call it French   \n",
       "3                                                                       \n",
       "4                                                    Or, ne peut pas.   \n",
       "\n",
       "                                              Zero_Shot_Pred_3  \\\n",
       "0                        Le ingénieur de lift ou le réception?   \n",
       "1       Je pense que elle s'est sa mère sa couleur sa couleur.   \n",
       "2  Si cela est ce qui vous pouvez ne peux pas s'est-elle-même.   \n",
       "3                                                                \n",
       "4                                             Or, ne peut pas.   \n",
       "\n",
       "                                            One_Shot_Pred_1  \\\n",
       "0                    Le ingénieur de lift ou le réception?    \n",
       "1  Je pense que elle s'est tellement belle que elle s'est.    \n",
       "2           Je ne vous avez pas à rester là de rien faire.    \n",
       "3                                                             \n",
       "4                                      Or, ne peut pas pas.   \n",
       "\n",
       "                                                      One_Shot_Pred_2  \\\n",
       "0                                                                       \n",
       "1  Je pense que elle a sa mère s'est juste mais belle que elle s'est.   \n",
       "2                                 if that's what you can even call it   \n",
       "3                                                                       \n",
       "4                                                                       \n",
       "\n",
       "                                                             One_Shot_Pred_3  \\\n",
       "0                                  Le ingénieur de lift ou le reservisteur?    \n",
       "1                   Je pense que elle s'est tellement belle que elle s'est.    \n",
       "2  Vous avez tout à fait raison, je vais essayer de téléphoner à l'accueil.    \n",
       "3                                                                              \n",
       "4                                                       Or, ne peut pas pas.   \n",
       "\n",
       "                                            Few_Shot_Pred_1  \\\n",
       "0                    Le ingénieur de lift ou le réception?    \n",
       "1  Je pense que elle s'est tellement belle que elle s'est.    \n",
       "2                                   Si cela est l'un vrai!    \n",
       "3                                                             \n",
       "4                                          Or, ne peut pas.   \n",
       "\n",
       "                                                                                                                                   Few_Shot_Pred_2  \\\n",
       "0                                                                                                           Le ingénieur de lift ou le réception?    \n",
       "1                                                                                             Je pense que elle s'est aussi belle que elle s'est.    \n",
       "2  Si cela est l'unique de l'enseignement universitaire pour changer son comportement au quotidien, et pour encontrer son entourage à faire même.    \n",
       "3                                                                                                                         Are there chickens too?    \n",
       "4                                                                                                                                 Or, ne peut pas.   \n",
       "\n",
       "                                                                                                                                                                                Few_Shot_Pred_3  \n",
       "0                                                                                                                                                        Le ingénieur de lift ou le réception?   \n",
       "1                                                                                                                                      Je pense que elle s'est tellement belle que elle s'est.   \n",
       "2  Je peux aussi s'adresser à l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard de l'égard  \n",
       "3                                                                                                                                                                                                \n",
       "4                                                                                                                                                                              Or, ne peut pas.  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "df = create_translation_model_result(num_test_examples = 100, output_csv_file = 'Translation_Evaluation_100_samples.csv', random_sample = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_1</th>\n",
       "      <td>0.25992</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.248204</td>\n",
       "      <td>0.24477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_2</th>\n",
       "      <td>0.20455</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.193535</td>\n",
       "      <td>0.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero_Shot_Prompt_3</th>\n",
       "      <td>0.280298</td>\n",
       "      <td>0.105562</td>\n",
       "      <td>0.267427</td>\n",
       "      <td>0.264743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_1</th>\n",
       "      <td>0.239909</td>\n",
       "      <td>0.082398</td>\n",
       "      <td>0.227984</td>\n",
       "      <td>0.224784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_2</th>\n",
       "      <td>0.12633</td>\n",
       "      <td>0.041883</td>\n",
       "      <td>0.118497</td>\n",
       "      <td>0.116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One_Shot_Prompt_3</th>\n",
       "      <td>0.264272</td>\n",
       "      <td>0.087616</td>\n",
       "      <td>0.250971</td>\n",
       "      <td>0.248329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_1</th>\n",
       "      <td>0.249927</td>\n",
       "      <td>0.081767</td>\n",
       "      <td>0.237022</td>\n",
       "      <td>0.233343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_2</th>\n",
       "      <td>0.23116</td>\n",
       "      <td>0.07876</td>\n",
       "      <td>0.220261</td>\n",
       "      <td>0.217108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few_Shot_Prompt_3</th>\n",
       "      <td>0.259871</td>\n",
       "      <td>0.091511</td>\n",
       "      <td>0.24707</td>\n",
       "      <td>0.244429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rouge1    rouge2    rougeL rougeLSum\n",
       "Zero_Shot_Prompt_1   0.25992  0.088658  0.248204   0.24477\n",
       "Zero_Shot_Prompt_2   0.20455  0.066176  0.193535  0.190966\n",
       "Zero_Shot_Prompt_3  0.280298  0.105562  0.267427  0.264743\n",
       "One_Shot_Prompt_1   0.239909  0.082398  0.227984  0.224784\n",
       "One_Shot_Prompt_2    0.12633  0.041883  0.118497  0.116902\n",
       "One_Shot_Prompt_3   0.264272  0.087616  0.250971  0.248329\n",
       "Few_Shot_Prompt_1   0.249927  0.081767  0.237022  0.233343\n",
       "Few_Shot_Prompt_2    0.23116   0.07876  0.220261  0.217108\n",
       "Few_Shot_Prompt_3   0.259871  0.091511   0.24707  0.244429"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = create_rouge_eval_result(df, output_csv_file = 'Translation_Evaluation_100_samples_Metrics.csv', gold_column = 'Gold Targets') \n",
    "df_res.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 Summary\n",
    "1. The results are comparatively similar in all the cases\n",
    "2. The results can be improvised by\n",
    "   - Experimenting with other prompts\n",
    "   - Experimenting with different configuration parameters of the model (e.g: do_sample=True for different decoding strategies)\n",
    "   - Perform fine-tuning on data\n",
    "   - Using larger parameters model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Programmatically print the names of all the model layers and their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([32128, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.final_layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.final_layer_norm.weight torch.Size([512])\n",
      "lm_head.weight torch.Size([32128, 512])\n"
     ]
    }
   ],
   "source": [
    "model_name=\"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Programmatically print the total number of parameters/weights in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 76961152\n"
     ]
    }
   ],
   "source": [
    "def print_numbers_of_parameters(model):\n",
    "    num_params=0\n",
    "    for param in model.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(f\"Total Parameters: {num_params}\")\n",
    "  \n",
    "print_numbers_of_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Set the tensor in final layer (decoder.final_layer_norm.weight) to all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Weight:\n",
      "torch.Size([512])\n",
      "tensor([ 0.1558,  0.1646,  0.1820,  0.2079,  0.1589,  0.1422,  0.1585,  0.1427,\n",
      "         0.1365,  0.1570,  0.1667,  0.1327,  0.1798,  0.3268,  0.2090,  0.2623,\n",
      "         0.1838,  0.1857,  0.1811,  0.1959,  0.1546,  0.2135,  0.1513,  0.1635,\n",
      "         0.1806,  0.1441,  0.1797,  0.2065,  0.1790,  0.2043,  0.1641,  0.1499,\n",
      "         0.1387,  0.2249,  0.1704,  0.6170,  0.1823,  0.1758,  0.1611,  0.2402,\n",
      "         0.1628,  0.2287,  0.1613,  0.1843,  0.2164,  0.2677,  0.1847,  0.1596,\n",
      "         0.2500,  0.1959,  0.1547,  0.2002,  0.1702,  0.1439,  0.1979,  0.1590,\n",
      "         0.1490,  0.1504,  0.2603,  0.1593,  0.1508,  0.2010,  0.1984,  0.1558,\n",
      "         0.1526,  0.1565,  0.1676,  0.7530,  0.1664,  0.1540,  0.0463,  0.1646,\n",
      "        -0.0066,  0.1754,  0.1569,  0.2540,  0.1964,  0.2072,  0.2011,  0.2037,\n",
      "         0.2167,  0.1654,  0.1696,  0.1270,  0.1451,  0.1714,  0.1802,  0.1709,\n",
      "         0.1647,  0.2128,  0.1757,  0.1353,  0.1522,  0.1424,  0.1464,  0.2132,\n",
      "         0.1656,  0.3751,  0.1328,  0.1482], grad_fn=<SliceBackward0>)\n",
      "Weight after Setting to zeros:\n",
      "torch.Size([512])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name=\"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "print('Original Weight:')\n",
    "print(model.decoder.final_layer_norm.weight.shape)\n",
    "print(model.decoder.final_layer_norm.weight[:100])\n",
    "model.decoder.final_layer_norm.weight = torch.nn.parameter.Parameter(model.decoder.final_layer_norm.weight*0)\n",
    "print('Weight after Setting to zeros:')\n",
    "print(model.decoder.final_layer_norm.weight.shape)\n",
    "print(model.decoder.final_layer_norm.weight[:100])\n",
    "model.save_pretrained(\"updated_flant5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"updated_flant5-small\")\n",
    "print(model.decoder.final_layer_norm.weight[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Verify if the Q&A task works after resetting the weights of the above layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [35:54<00:00, 21.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index  \\\n",
      "0      0   \n",
      "1      1   \n",
      "2      2   \n",
      "3      3   \n",
      "4      4   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Context  \\\n",
      "0  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
      "1  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
      "2  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
      "3  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
      "4  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.   \n",
      "\n",
      "                                                           Question  \\\n",
      "0                              In what country is Normandy located?   \n",
      "1                                When were the Normans in Normandy?   \n",
      "2                     From which countries did the Norse originate?   \n",
      "3                                         Who was the Norse leader?   \n",
      "4  What century did the Normans first gain their separate identity?   \n",
      "\n",
      "                  Gold Summary Zero_Shot_Pred_1 Zero_Shot_Pred_2  \\\n",
      "0                       France                                     \n",
      "1      10th and 11th centuries                                     \n",
      "2  Denmark, Iceland and Norway                                     \n",
      "3                        Rollo                                     \n",
      "4                 10th century                                     \n",
      "\n",
      "  Zero_Shot_Pred_3 One_Shot_Pred_1 One_Shot_Pred_2 One_Shot_Pred_3  \\\n",
      "0                                                                    \n",
      "1                                                                    \n",
      "2                                                                    \n",
      "3                                                                    \n",
      "4                                                                    \n",
      "\n",
      "  Few_Shot_Pred_1 Few_Shot_Pred_2 Few_Shot_Pred_3  \n",
      "0                                                  \n",
      "1                                                  \n",
      "2                                                  \n",
      "3                                                  \n",
      "4                                                  \n",
      "                   rouge1 rouge2 rougeL rougeLSum\n",
      "Zero_Shot_Prompt_1    0.0    0.0    0.0       0.0\n",
      "Zero_Shot_Prompt_2    0.0    0.0    0.0       0.0\n",
      "Zero_Shot_Prompt_3    0.0    0.0    0.0       0.0\n",
      "One_Shot_Prompt_1     0.0    0.0    0.0       0.0\n",
      "One_Shot_Prompt_2     0.0    0.0    0.0       0.0\n",
      "One_Shot_Prompt_3     0.0    0.0    0.0       0.0\n",
      "Few_Shot_Prompt_1     0.0    0.0    0.0       0.0\n",
      "Few_Shot_Prompt_2     0.0    0.0    0.0       0.0\n",
      "Few_Shot_Prompt_3     0.0    0.0    0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"updated_flant5-small\")\n",
    "\n",
    "df = create_qa_model_result(num_test_examples = 100, output_csv_file = 'QA_Updated_Evaluation_100_samples.csv', random_sample = False)\n",
    "print(df.head())\n",
    "\n",
    "df_res = create_rouge_eval_result(df, output_csv_file = 'QA_Updated_Evaluation_100_samples_Metrics.csv', gold_column = 'Gold Summary') \n",
    "print(df_res.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Q&A Task does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Original Weights:\n",
      "model.decoder.final_layer_norm.weight.shape:  torch.Size([512])\n",
      "model.lm_head.weight.shape:  torch.Size([32128, 512])\n",
      "\n",
      "== Weights after reducing dimension:\n",
      "torch.Size([256])\n",
      "torch.Size([32128, 256])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"updated_flant5-small\")\n",
    "\n",
    "print('== Original Weights:')\n",
    "print(f\"model.decoder.final_layer_norm.weight.shape: \",model.decoder.final_layer_norm.weight.shape)\n",
    "print(f\"model.lm_head.weight.shape: \",model.lm_head.weight.shape)\n",
    "\n",
    "new_dimension = 256\n",
    "\n",
    "model.decoder.final_layer_norm.weight = torch.nn.parameter.Parameter(torch.zeros(new_dimension))\n",
    "original_weight = model.lm_head.weight.clone()\n",
    "model.lm_head.weight = torch.nn.Parameter(torch.zeros(original_weight.size(0),new_dimension))\n",
    "model.lm_head.weight = torch.nn.Parameter(original_weight[:,:new_dimension])\n",
    "\n",
    "print('\\n== Weights after reducing dimension:')\n",
    "print(model.decoder.final_layer_norm.weight.shape)\n",
    "print(model.lm_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([32128, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.final_layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.final_layer_norm.weight torch.Size([256])\n",
      "lm_head.weight torch.Size([32128, 256])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([32128, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "encoder.final_layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([512])\n",
      "decoder.final_layer_norm.weight torch.Size([512])\n",
      "lm_head.weight torch.Size([32128, 512])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"updated_flant5-small\")\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "new_dimension = 256\n",
    "\n",
    "# Update shared.weight\n",
    "model.shared.weight = torch.nn.Parameter(\n",
    "    model.shared.weight[:, :new_dimension])\n",
    "\n",
    "# Update encoder block layers\n",
    "num_encoder_blocks = 8\n",
    "for i in range(num_encoder_blocks):\n",
    "\n",
    "    # Update SelfAttention.weight\n",
    "    model.encoder.block[i].layer[0].SelfAttention.q.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[0].SelfAttention.q.weight[:, :new_dimension])\n",
    "    model.encoder.block[i].layer[0].SelfAttention.k.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[0].SelfAttention.k.weight[:, :new_dimension])\n",
    "    model.encoder.block[i].layer[0].SelfAttention.v.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[0].SelfAttention.v.weight[:, :new_dimension])\n",
    "    model.encoder.block[i].layer[0].SelfAttention.o.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[0].SelfAttention.o.weight[:new_dimension, :])\n",
    "\n",
    "    # Update layer_norm.weight\n",
    "    model.encoder.block[i].layer[0].layer_norm.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[0].layer_norm.weight[:new_dimension])\n",
    "    model.encoder.block[i].layer[1].layer_norm.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[1].layer_norm.weight[:new_dimension])\n",
    "\n",
    "    # Update DenseReluDense.wo.weight\n",
    "    model.encoder.block[i].layer[1].DenseReluDense.wi_0.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[1].DenseReluDense.wi_0.weight[:new_dimension*2,:new_dimension])\n",
    "    model.encoder.block[i].layer[1].DenseReluDense.wi_1.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[1].DenseReluDense.wi_1.weight[:new_dimension*2,:new_dimension])\n",
    "    model.encoder.block[i].layer[1].DenseReluDense.wo.weight = torch.nn.Parameter(\n",
    "        model.encoder.block[i].layer[1].DenseReluDense.wo.weight[:new_dimension, :new_dimension*2])\n",
    "\n",
    "# Update encoder final_layer_norm.weight\n",
    "model.encoder.final_layer_norm.weight = torch.nn.Parameter(\n",
    "    model.encoder.final_layer_norm.weight[:new_dimension])\n",
    "\n",
    "\n",
    "# Update decoder block layers\n",
    "num_decoder_blocks = 8\n",
    "for i in range(num_decoder_blocks):\n",
    "    \n",
    "    # Update SelfAttention.weight\n",
    "    model.decoder.block[i].layer[0].SelfAttention.q.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[0].SelfAttention.q.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[0].SelfAttention.k.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[0].SelfAttention.k.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[0].SelfAttention.v.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[0].SelfAttention.v.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[0].SelfAttention.o.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[0].SelfAttention.o.weight[:new_dimension, :])\n",
    "\n",
    "    # Update layer_norm.weight\n",
    "    model.decoder.block[i].layer[0].layer_norm.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[0].layer_norm.weight[:new_dimension])\n",
    "    model.decoder.block[i].layer[1].layer_norm.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[1].layer_norm.weight[:new_dimension])\n",
    "    model.decoder.block[i].layer[2].layer_norm.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[2].layer_norm.weight[:new_dimension])\n",
    "\n",
    "    # Update EncDecAttention.weight\n",
    "    model.decoder.block[i].layer[1].EncDecAttention.q.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.q.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[1].EncDecAttention.k.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.k.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[1].EncDecAttention.v.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.v.weight[:, :new_dimension])\n",
    "    model.decoder.block[i].layer[1].EncDecAttention.o.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.o.weight[:new_dimension,:])\n",
    "\n",
    "    # Update DenseReluDense.wo.weight\n",
    "    model.decoder.block[i].layer[2].DenseReluDense.wi_0.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[2].DenseReluDense.wi_0.weight[:new_dimension*2,:new_dimension])\n",
    "    model.decoder.block[i].layer[2].DenseReluDense.wi_1.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[2].DenseReluDense.wi_1.weight[:new_dimension*2,:new_dimension])\n",
    "    model.decoder.block[i].layer[2].DenseReluDense.wo.weight = torch.nn.Parameter(\n",
    "        model.decoder.block[i].layer[2].DenseReluDense.wo.weight[:new_dimension, :new_dimension*2])\n",
    "\n",
    "# Update decoder final_layer_norm.weight\n",
    "model.decoder.final_layer_norm.weight = torch.nn.Parameter(\n",
    "    model.decoder.final_layer_norm.weight[:new_dimension])\n",
    "\n",
    "# Update lm_head.weight\n",
    "model.lm_head.weight = torch.nn.Parameter(\n",
    "    model.lm_head.weight[:, :new_dimension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([32128, 256])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([256])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([256])\n",
      "encoder.final_layer_norm.weight torch.Size([256])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([256])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([384, 256])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([256, 384])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([256])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([512, 256])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([512, 256])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([256, 512])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([256])\n",
      "decoder.final_layer_norm.weight torch.Size([256])\n",
      "lm_head.weight torch.Size([32128, 256])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Reload the original google/flan-t5-small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name=\"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11: Train the model for a Q&A task that takes context as additional input along with the question. You can use SQuAD dataset (https://rajpurkar.github.io/SQuAD-explorer/ ) or the smaller Topioca dataset (h_ps://mcgill-nlp.github.io/topiocqa/). Choose an appropriate task prefix/trigger word and justify the choice.\n",
    "\n",
    "I am fine-tuning on SQuAD dataset using Parameter Efficient Fine-Tuning (PEFT) technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"google/flan-t5-small\", \n",
    "    load_in_8bit=True, \n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rajpurkar/squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Instruction-based dataset\n",
    "\n",
    "def tokenize_function(example):\n",
    "\n",
    "    prompts = []\n",
    "    for context,question in zip(example[\"context\"],example[\"question\"]):\n",
    "        prompts.append(f\"\"\"Given a Context and a Question, utilize the context to answer the question. Don't use any other information\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\"\"\")\n",
    "\n",
    "    answers = []\n",
    "    for answer in example[\"answers\"]:\n",
    "        ans=''\n",
    "        if 'text' in answer and len(answer['text'])>0:\n",
    "            ans = answer['text'][0]\n",
    "        answers.append(ans)\n",
    "\n",
    "    example['input_ids'] = tokenizer(prompts, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(answers, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 5 == 0, with_indices=True)\n",
    "\n",
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model , TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "output_dir = 'peft-squadv2-qa-training'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=1,\n",
    "    max_steps=10    \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"peft-squad-v2-qa-checkpoints\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       'peft-squad-v2-qa-checkpoints/', \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_prediction(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    peft_model_outputs = model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "    output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "    output = re.sub('---*','',str(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12: Evaluate the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Unnamed: 0    rouge1    rouge2    rougeL  rougeLSum\n",
      "0  Zero_Shot_Prompt_1  0.372387  0.159821  0.375336   0.373538\n",
      "1  Zero_Shot_Prompt_2  0.369750  0.156583  0.371631   0.369631\n",
      "2  Zero_Shot_Prompt_3  0.345125  0.151690  0.348074   0.344720\n",
      "3   One_Shot_Prompt_1  0.353196  0.149690  0.357905   0.354684\n",
      "4   One_Shot_Prompt_2  0.351934  0.149690  0.356725   0.353705\n",
      "5   One_Shot_Prompt_3  0.353835  0.155524  0.358135   0.354820\n",
      "6   Few_Shot_Prompt_1  0.352333  0.137214  0.355655   0.352857\n",
      "7   Few_Shot_Prompt_2  0.344083  0.143940  0.348901   0.345777\n",
      "8   Few_Shot_Prompt_3  0.353351  0.134857  0.356560   0.353800\n"
     ]
    }
   ],
   "source": [
    "model = peft_model\n",
    "\n",
    "df = create_qa_model_result(num_test_examples = 100, output_csv_file = 'QA_PEFT_Evaluation_100_samples.csv', random_sample = False)\n",
    "print(df.head())\n",
    "\n",
    "df_res = create_rouge_eval_result(df, output_csv_file = 'QA_PEFT_Evaluation_100_samples_Metrics.csv', gold_column = 'Gold Summary') \n",
    "print(df_res.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "1. The results are almost similar or slightly better than the In-Context Learning-based approach.\n",
    "2. The results can be improvised by\n",
    "    - fine-tuning on more data\n",
    "    - experimenting with other prompts\n",
    "    - using a larger parameter model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
